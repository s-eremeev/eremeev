{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кадры решают всё (но это не точно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кадры, да..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# импорт библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import shutil  # упаковка в архив\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\")\n",
    "\n",
    "# путь к безликим\n",
    "unpersonal_path = 'C:/personal_auto/unpersonal/'\n",
    "\n",
    "# список файлов в целевой директории\n",
    "source_files_list = os.listdir(unpersonal_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dt = pd.DataFrame()\n",
    "for file in source_files_list:\n",
    "    df_tmp = pd.read_csv(\n",
    "        unpersonal_path + file,\n",
    "        sep=\";\",\n",
    "        encoding=\"ansi\",\n",
    "    )\n",
    "    df_dt = pd.concat([df_dt, df_tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dt = df_dt.replace(\",\", \".\", regex=True).apply(pd.to_numeric, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dt['3. Адрес МО. Наим. субъекта РФ'] = df_dt['3. Адрес МО. Наим. субъекта РФ'].fillna('не определён')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Поиск и замена регионов, имеющих различные наименования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regions = pd.DataFrame(df_dt['3. Адрес МО. Наим. субъекта РФ']).drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3. Адрес МО. Наим. субъекта РФ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>не определён</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Алтайский край</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Амурская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Архангельская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Астраханская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Белгородская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Брянская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Владимирская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Волгоградская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Вологодская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Воронежская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>г. Байконур</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>г. Москва</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>г. Санкт-Петербург</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>г. Севастополь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Донецкая Народная Республика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Еврейская автономная область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Забайкальский край</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Запорожская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ивановская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Иркутская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Кабардино-Балкарская Республика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Калининградская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Калужская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Камчатский край</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Карачаево-Черкесская Республика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Кемеровская область - Кузбасс</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Кемеровская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Кировская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Костромская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Краснодарский край</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Красноярский край</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Курганская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Курская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ленинградская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Липецкая область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Луганская Народная Республика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Магаданская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Московская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Мурманская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Ненецкий автономный округ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Нижегородская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Новгородская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Новосибирская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Омская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Оренбургская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Орловская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Пензенская область</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Пермский край</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Приморский край</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     3. Адрес МО. Наим. субъекта РФ\n",
       "0                      не определён\n",
       "1                    Алтайский край\n",
       "2                  Амурская область\n",
       "3             Архангельская область\n",
       "4              Астраханская область\n",
       "5              Белгородская область\n",
       "6                  Брянская область\n",
       "7              Владимирская область\n",
       "8             Волгоградская область\n",
       "9               Вологодская область\n",
       "10              Воронежская область\n",
       "11                      г. Байконур\n",
       "12                        г. Москва\n",
       "13               г. Санкт-Петербург\n",
       "14                   г. Севастополь\n",
       "15     Донецкая Народная Республика\n",
       "16     Еврейская автономная область\n",
       "17               Забайкальский край\n",
       "18              Запорожская область\n",
       "19               Ивановская область\n",
       "20                Иркутская область\n",
       "21  Кабардино-Балкарская Республика\n",
       "22          Калининградская область\n",
       "23                Калужская область\n",
       "24                  Камчатский край\n",
       "25  Карачаево-Черкесская Республика\n",
       "26    Кемеровская область - Кузбасс\n",
       "27              Кемеровская область\n",
       "28                Кировская область\n",
       "29              Костромская область\n",
       "30               Краснодарский край\n",
       "31                Красноярский край\n",
       "32               Курганская область\n",
       "33                  Курская область\n",
       "34            Ленинградская область\n",
       "35                 Липецкая область\n",
       "36    Луганская Народная Республика\n",
       "37              Магаданская область\n",
       "38               Московская область\n",
       "39               Мурманская область\n",
       "40        Ненецкий автономный округ\n",
       "41            Нижегородская область\n",
       "42             Новгородская область\n",
       "43            Новосибирская область\n",
       "44                   Омская область\n",
       "45             Оренбургская область\n",
       "46                Орловская область\n",
       "47               Пензенская область\n",
       "48                    Пермский край\n",
       "49                  Приморский край"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_regions.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сравнение текстов - не поможет, к сожалению\n",
    "import difflib\n",
    "\n",
    "def similarity(s1, s2):\n",
    "  \"\"\"сравнение текстов\"\"\"\n",
    "  normalized1 = s1.lower()\n",
    "  normalized2 = s2.lower()\n",
    "  matcher = difflib.SequenceMatcher(None, normalized1, normalized2)\n",
    "  return matcher.ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "s1 = 'Краснодартский край'\n",
    "s2 = 'Красноярский край'\n",
    "print(similarity(s1, s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words(string):\n",
    "    \"\"\"преобразование строки в список, элементами которого являются\n",
    "    части строки, разбитой по неалфавитным символам. Все элементы списка\n",
    "    приведены к нижнему регистру\"\"\"\n",
    "    str = ''\n",
    "    for symbol in string:\n",
    "        symbol = symbol if symbol.isalpha() else '$'\n",
    "        str = str + symbol\n",
    "    lst = str.split('$')\n",
    "    while '' in lst:\n",
    "        lst.remove('')\n",
    "    return [element.lower() for element in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_1 = 'Луганская Народная Республика'\n",
    "s_2 = 'Донецкая Народная Республика'\n",
    "result_1 = words(s_1)\n",
    "result_2 = words(s_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = result_1 + result_2\n",
    "ratio = len(set(lst))/len(lst)\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8421052631578947"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(s_1, s_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.0 - совсем разные   \n",
    "0.75 - один тип субъекта РФ   \n",
    "0.6 - есть что-то общее   \n",
    "если ratio < 0.60 - это один субъект   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['татарская', 'республика', 'татарстан']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяем количество файлов в целевой директории\n",
    "if len(source_file) == 0:\n",
    "    print(\"Нет целевого файла, программа завершает работу\")\n",
    "    sys.exit()\n",
    "elif len(source_file) > 1:\n",
    "    print(f\"В целевой директории {len(source_file)} файла(ов)\")\n",
    "    # тогда будем использовать файл с максимальным временем модификации\n",
    "    # словарь для хранения времени модификации (ключ) файлов (значение)\n",
    "    dict_ = {}\n",
    "    # список времён модификации файлов\n",
    "    list_ = []\n",
    "    for file in source_file:\n",
    "        path = soutce_path + file\n",
    "        mtime = os.path.getmtime(path)\n",
    "        dict_[mtime] = file\n",
    "        list_.append(mtime)\n",
    "    list_.sort(reverse=True)\n",
    "    source_file_result = dict_[list_[0]]\n",
    "    print(\n",
    "        f\"Для работы используется файл {source_file_result}, имеющий наиболее позднее время модификации\\nЕсли это не то, что вам нужно, измените содержимое целевой директории\"\n",
    "    )\n",
    "else:\n",
    "    source_file_result = source_file[0]\n",
    "    print(f\"В целевой директории единственный файл {source_file_result}\")\n",
    "\n",
    "# путь к целевому файлу\n",
    "soutce_file_path = soutce_path + source_file_result\n",
    "\n",
    "# префикс для имён файлов-результатов\n",
    "pref = source_file_result.split(\".\")[0]\n",
    "\n",
    "# полный путь к итоговому экселевскому файлу ФЛК-1,2\n",
    "result_12_exc_path = result_12_exc_path + pref + \"_flk12_result.xlsx\"\n",
    "# полный путь к итоговому файлу ФЛК-3\n",
    "result_3_path = result_3_path + pref + \"_flk3_result.csv\"\n",
    "# полный путь к архиву\n",
    "result_12_files_path_arch = result_12_files_path_arch + pref + \"_flk12_result\"\n",
    "\n",
    "\n",
    "# ФЛК-1, 2\n",
    "\n",
    "# данные для фильтрации исходного файла\n",
    "last_status = [\"На согласовании\", \"На редактировании (после отклонения)\", \"Запрос на отклонение\", \"Согласовано\"]\n",
    "# last_status = [\"На согласовании\", \"На редактировании (после отклонения)\"]\n",
    "last_status_date = \"2020-07-10\"  # сначала год, месяц, потом число. Отчётный период начинается в 00:00 указанной даты\n",
    "next_status_date = \"2073-07-03\"  # и продолжается до 23:59 даты перед конечной\n",
    "\n",
    "print(f\"Статус: {last_status}\")\n",
    "print(f\"Дата начала: {last_status_date}\")\n",
    "print(f\"Дата окончания: {next_status_date}\")\n",
    "\n",
    "# сделать пустые фреймы для всех фреймов ошибок для корректной выгруки в Excel\n",
    "\n",
    "# удаление всех фреймов, оставшихся (вдруг) от предыдущей работы скрипта\n",
    "try:\n",
    "    del df_notation\n",
    "except Exception:\n",
    "    pass\n",
    "try:\n",
    "    del df_ass_0\n",
    "except Exception:\n",
    "    pass\n",
    "try:\n",
    "    del df_ass\n",
    "except Exception:\n",
    "    pass\n",
    "try:\n",
    "    del df_ass_success\n",
    "except Exception:\n",
    "    pass\n",
    "try:\n",
    "    del df_ass_error\n",
    "except Exception:\n",
    "    pass\n",
    "try:\n",
    "    del df_mo_error\n",
    "except Exception:\n",
    "    pass\n",
    "try:\n",
    "    del df_dept_error\n",
    "except Exception:\n",
    "    pass\n",
    "try:\n",
    "    del df_ass_erorr_sum\n",
    "except Exception:\n",
    "    pass\n",
    "try:\n",
    "    del df_mo_count_more_save\n",
    "except Exception:\n",
    "    pass\n",
    "try:\n",
    "    del df_ass_mo_plan_zero\n",
    "except Exception:\n",
    "    pass\n",
    "try:\n",
    "    del df_ass_mo_fact_zero\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "\n",
    "# пустые фреймы для будущих ошибок (без них вылетает сохранение в excel, когда нет ошибок)\n",
    "df_dept_error = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"id СП\",\n",
    "        \"Регион\",\n",
    "        \"наименование оборудования\",\n",
    "        \"непосредственно заявка СП\",\n",
    "        \"сумма заявок по кабинетам\",\n",
    "    ]\n",
    ")\n",
    "df_mo_error = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"id МО\",\n",
    "        \"Регион\",\n",
    "        \"наименование оборудования\",\n",
    "        \"непосредственно заявка МО\",\n",
    "        \"сумма заявок по СП\",\n",
    "    ]\n",
    ")\n",
    "df_ass_mo_plan_zero = pd.DataFrame()\n",
    "df_ass_mo_fact_zero = pd.DataFrame()\n",
    "\n",
    "# загрузка исходного файла - путь изменён!\n",
    "df_ass = pd.read_csv(\n",
    "    soutce_file_path,\n",
    "    sep=\";\",\n",
    "    header=1,\n",
    "    encoding=\"utf-8-sig\",\n",
    ")\n",
    "\n",
    "# проверка наличия новых столбцов\n",
    "if (\n",
    "    df_ass.columns[1] != \"Текущий статус\"\n",
    "    or df_ass.columns[2] != \"Дата последнего статуса\"\n",
    "):\n",
    "    print(\"Неверная структура исходных данных\")\n",
    "else:\n",
    "    print(\"Структура исходных данных верная\")\n",
    "\n",
    "# преобразование формата даты для фильтрации\n",
    "# df_ass[\"Дата последнего статуса\"] = df_ass[\"Дата последнего статуса\"].astype(\"datetime64[ns]\", format = \"%d.%m.%Y %H:%M:%S\")\n",
    "df_ass[\"Дата последнего статуса\"] = pd.to_datetime(\n",
    "    df_ass[\"Дата последнего статуса\"], format=\"%d.%m.%Y %H:%M:%S\"\n",
    ")\n",
    "\n",
    "# копия исходника для потомков\n",
    "df_ass_0 = df_ass.copy()\n",
    "\n",
    "# фильтрация по статусу и последней дате, удаление столбцов статуса и последней даты\n",
    "df_ass = df_ass[df_ass[\"Текущий статус\"].isin(last_status)]\n",
    "df_ass = df_ass[df_ass[\"Дата последнего статуса\"] >= last_status_date]\n",
    "df_ass = df_ass[df_ass[\"Дата последнего статуса\"] < next_status_date]\n",
    "df_ass = df_ass.reset_index(drop=True)\n",
    "# сначала сохраним в файл для контроля\n",
    "df_ass.to_csv(\n",
    "    result_12_files_path + \"/исходные_данные_до_удаления_столбцов.csv\",\n",
    "    sep=\";\",\n",
    "    encoding=\"utf-8-sig\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "cols = [1, 2]\n",
    "df_ass = df_ass.drop(df_ass.columns[cols], axis=1)\n",
    "# теперь получаем нормальный исходник, с которым работали до с самого начала, а не вот это вот всё\n",
    "# дальше работаем так, словно ничего в исходнике не менялось\n",
    "\n",
    "\n",
    "# очистка полностю пустых строк\n",
    "row_count_0 = df_ass.shape[0]\n",
    "df_ass = df_ass.dropna(how=\"all\")\n",
    "print(f\"Удалено {row_count_0 - df_ass.shape[0]} полностью пустых строк\")\n",
    "\n",
    "# заполнение пустых значений вниз\n",
    "df_ass[df_ass.columns[0]] = df_ass[[df_ass.columns[0]]].ffill(axis=0)\n",
    "df_ass[df_ass.columns[6]] = df_ass[[df_ass.columns[6]]].ffill(axis=0)\n",
    "df_ass[df_ass.columns[7]] = df_ass[[df_ass.columns[7]]].ffill(axis=0)\n",
    "\n",
    "# замена пропусков на 0\n",
    "df_ass = df_ass.fillna(0)\n",
    "\n",
    "# сохранение результата в файл\n",
    "df_ass.to_csv(\n",
    "    result_12_files_path + \"/исходные_данные(.csv).csv\",\n",
    "    sep=\";\",\n",
    "    encoding=\"utf-8-sig\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "# добавление столбца уровня лечебницы\n",
    "df_ass = df_ass.astype({df_ass.columns[1]: \"str\"})\n",
    "df_ass[\"lvl\"] = df_ass.apply(lambda x: len(x[df_ass.columns[1]].split(\"_\")) - 2, axis=1)\n",
    "\n",
    "# переименование столбца с некошерным названием\n",
    "df_ass = df_ass.rename(columns={df_ass.columns[1]: \"ID\"})\n",
    "\n",
    "# разделение на фреймы МО, СП и кабинетов, удаление ненужных данных\n",
    "df_ass_mo = df_ass[df_ass[\"lvl\"] == 0].reset_index(drop=True)\n",
    "df_ass_dept = df_ass[df_ass[\"lvl\"] == 1].reset_index(drop=True)\n",
    "df_ass_room = df_ass[df_ass[\"lvl\"] == 2].reset_index(drop=True)\n",
    "df_ass_mo.drop(\n",
    "    [\n",
    "        df_ass.columns[0],\n",
    "        df_ass.columns[2],\n",
    "        df_ass.columns[3],\n",
    "        df_ass.columns[4],\n",
    "        df_ass.columns[5],\n",
    "        df_ass.columns[6],\n",
    "        df_ass.columns[7],\n",
    "        df_ass.columns[8],\n",
    "        \"lvl\",\n",
    "    ],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")\n",
    "df_ass_dept.drop(\n",
    "    [\n",
    "        df_ass.columns[0],\n",
    "        df_ass.columns[2],\n",
    "        df_ass.columns[3],\n",
    "        df_ass.columns[4],\n",
    "        df_ass.columns[5],\n",
    "        df_ass.columns[6],\n",
    "        df_ass.columns[7],\n",
    "        df_ass.columns[8],\n",
    "        \"lvl\",\n",
    "    ],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")\n",
    "df_ass_room.drop(\n",
    "    [\n",
    "        df_ass.columns[0],\n",
    "        df_ass.columns[2],\n",
    "        df_ass.columns[3],\n",
    "        df_ass.columns[4],\n",
    "        df_ass.columns[5],\n",
    "        df_ass.columns[6],\n",
    "        df_ass.columns[7],\n",
    "        df_ass.columns[8],\n",
    "        \"lvl\",\n",
    "    ],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# а что, если в фрейме МО какие-то лечебницы встречаются более одного раза?\n",
    "df_mo_count = pd.DataFrame(df_ass_mo[\"ID\"].value_counts()).reset_index()\n",
    "df_mo_count_more = df_mo_count[df_mo_count[\"count\"] > 1]\n",
    "df_mo_count_more_save = df_mo_count_more.merge(\n",
    "    df_ass, left_on=\"ID\", right_on=\"ID\", how=\"left\"\n",
    ")  # для сохранения\n",
    "# удалим из сохраняемого фрейма столбцы, заполненные в данном случае - при повторяющихся кодах лечебниц - некорректно\n",
    "df_mo_count_more_save = df_mo_count_more_save.drop(\n",
    "    [\n",
    "        \"Регион\",\n",
    "        \"Численность прикрепленного населения\",\n",
    "        \"Численность обслуживаемого населения \",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "if len(df_mo_count_more[\"ID\"].tolist()) > 0:\n",
    "    print(\"Внимание! В исходных данных повторяются следующие МО:\")\n",
    "    print(*df_mo_count_more[\"ID\"].tolist(), sep=\"\\n\")\n",
    "else:\n",
    "    print(\"Коды МО в исходных данных не повторяются\")\n",
    "\n",
    "# а что ести какие-то фреймы пусты?\n",
    "flag = 0  # показатель уровня иерархии\n",
    "if df_ass_dept.empty:\n",
    "    flag = 1\n",
    "    print(\"Иерархия данных отсутствует, представлены только МО\")\n",
    "if df_ass_room.empty:\n",
    "    flag = 2\n",
    "    print(\"Представлены данные по МО и подразделениям, кабинетов нет\")\n",
    "\n",
    "\n",
    "if flag == 0:  # есть и МО, и СП, и кабинеты\n",
    "    print(\"Структура данных полная, есть и МО, и СП, и кабинеты\")\n",
    "    # добавление в фреймы СП и кабинетов id более выского уровня иерархии\n",
    "    df_ass_dept.insert(\n",
    "        1, \"id\", df_ass_dept.apply(lambda x: \"_\".join(x[\"ID\"].split(\"_\")[:-1]), axis=1)\n",
    "    )\n",
    "    df_ass_room.insert(\n",
    "        1, \"id\", df_ass_room.apply(lambda x: \"_\".join(x[\"ID\"].split(\"_\")[:-1]), axis=1)\n",
    "    )\n",
    "\n",
    "    # группировка фреймов СП и кабинетов по более высокому уровню иерархии\n",
    "    df_ass_dept_group_mo = df_ass_dept.groupby(\"id\").sum().reset_index()\n",
    "    df_ass_dept_group_room = df_ass_dept.groupby(\"ID\").sum().reset_index()\n",
    "    df_ass_room_group = df_ass_room.groupby(\"id\").sum().reset_index()\n",
    "    df_ass_dept_group_mo.drop([\"ID\"], axis=1, inplace=True)\n",
    "    df_ass_dept_group_room.drop([\"id\"], axis=1, inplace=True)\n",
    "    df_ass_room_group.drop([\"ID\"], axis=1, inplace=True)\n",
    "\n",
    "    # добавление данных об источнике\n",
    "    df_ass_mo.insert(1, \"source\", \"mo\")\n",
    "    df_ass_mo = df_ass_mo.rename(columns={\"ID\": \"id\"})\n",
    "    df_ass_dept_group_mo.insert(1, \"source\", \"dept\")\n",
    "    df_ass_dept_group_room.insert(1, \"source\", \"dept\")\n",
    "    df_ass_dept_group_room = df_ass_dept_group_room.rename(columns={\"ID\": \"id\"})\n",
    "    df_ass_room_group.insert(1, \"source\", \"room\")\n",
    "\n",
    "    # соединение фреймов\n",
    "    df_mo = (\n",
    "        pd.concat([df_ass_mo, df_ass_dept_group_mo])\n",
    "        .sort_values([\"id\"], ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    df_dept = (\n",
    "        pd.concat([df_ass_dept_group_room, df_ass_room_group])\n",
    "        .sort_values([\"id\"], ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # формирование спиков кодов лечебниц строк с повторяющимися кодами лечебниц\n",
    "    mo_index_list = []\n",
    "    for index in range(0, df_mo.shape[0] - 1):\n",
    "        if df_mo.loc[index][\"id\"] == df_mo.loc[index + 1][\"id\"]:\n",
    "            mo_index_list.append(df_mo.loc[index][\"id\"])\n",
    "\n",
    "    dept_index_list = []\n",
    "    for index in range(0, df_dept.shape[0] - 1):\n",
    "        if df_dept.loc[index][\"id\"] == df_dept.loc[index + 1][\"id\"]:\n",
    "            dept_index_list.append(df_dept.loc[index][\"id\"])\n",
    "\n",
    "    # удаление непарных строк\n",
    "    df_mo_result = df_mo.loc[df_mo[\"id\"].isin(mo_index_list)]\n",
    "    df_dept_result = df_dept.loc[df_dept[\"id\"].isin(dept_index_list)]\n",
    "    for column in df_mo_result.columns:\n",
    "        if df_mo_result[column].sum() == 0:\n",
    "            df_mo_result = df_mo_result.drop(column, axis=1)\n",
    "    df_mo_result = df_mo_result.reset_index(drop=True)\n",
    "\n",
    "    for column in df_dept_result.columns:\n",
    "        if df_dept_result[column].sum() == 0:\n",
    "            df_dept_result = df_dept_result.drop(column, axis=1)\n",
    "    df_dept_result = df_dept_result.reset_index(drop=True)\n",
    "\n",
    "elif flag == 2:  # нет кабинетов, только МО и СП\n",
    "    df_dept_result = pd.DataFrame()  # пустой фрейм для единообразия\n",
    "    df_ass_dept.insert(\n",
    "        1, \"id\", df_ass_dept.apply(lambda x: \"_\".join(x[\"ID\"].split(\"_\")[:-1]), axis=1)\n",
    "    )\n",
    "\n",
    "    # группировка фреймов СП и кабинетов по более высокому уровню иерархии\n",
    "    df_ass_dept_group_mo = df_ass_dept.groupby(\"id\").sum().reset_index()\n",
    "    df_ass_dept_group_mo.drop([\"ID\"], axis=1, inplace=True)\n",
    "\n",
    "    # добавление данных об источнике\n",
    "    df_ass_mo.insert(1, \"source\", \"mo\")\n",
    "    df_ass_mo = df_ass_mo.rename(columns={\"ID\": \"id\"})\n",
    "    df_ass_dept_group_mo.insert(1, \"source\", \"dept\")\n",
    "\n",
    "    # соединение фреймов\n",
    "    df_mo = (\n",
    "        pd.concat([df_ass_mo, df_ass_dept_group_mo])\n",
    "        .sort_values([\"id\"], ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # формирование списков кодов лечебниц строк с повторяющимися кодами лечебниц\n",
    "    mo_index_list = []\n",
    "    for index in range(0, df_mo.shape[0] - 1):\n",
    "        if df_mo.loc[index][\"id\"] == df_mo.loc[index + 1][\"id\"]:\n",
    "            mo_index_list.append(df_mo.loc[index][\"id\"])\n",
    "\n",
    "    # удаление непарных строк\n",
    "    df_mo_result = df_mo.loc[df_mo[\"id\"].isin(mo_index_list)]\n",
    "    for column in df_mo_result.columns:\n",
    "        if df_mo_result[column].sum() == 0:\n",
    "            df_mo_result = df_mo_result.drop(column, axis=1)\n",
    "    df_mo_result = df_mo_result.reset_index(drop=True)\n",
    "else:\n",
    "    print(\"Иерархия отсутстствует, нет предмета для проверки\")\n",
    "\n",
    "# удалим из исходных данных не нужный уже и вредный по сути столбец lvl\n",
    "df_ass = df_ass.drop(\"lvl\", axis=1)\n",
    "\n",
    "# собственно проверка соответствия количества оборудования\n",
    "\n",
    "# сделаем маленький кусочек исходного фрейма для присоединения к результатам\n",
    "df_ass_l = df_ass[[\"Регион\", \"ID\", \"Наименование МО\"]]\n",
    "\n",
    "# проверка df_mo_result\n",
    "mo_error = []\n",
    "for mo in df_mo_result[\"id\"].unique():\n",
    "    df_test_mo = df_mo_result[df_mo_result[\"id\"] == mo]\n",
    "    # проверка на количество строк в df_test_mo\n",
    "    # если строк не 2, вся информация сохраняется в файл и проверка такой МО не осуществляется\n",
    "    if df_test_mo.shape[0] != 2 or len(df_test_mo[\"source\"].unique()) != 2:\n",
    "        path = result_12_files_path + \"/\" + mo + \".csv\"\n",
    "        df_test_mo.to_csv(path, sep=\";\", encoding=\"utf-8-sig\", index=False)\n",
    "    else:\n",
    "        for column in df_test_mo.columns[2:]:\n",
    "            if (\n",
    "                df_test_mo.loc[df_test_mo[\"source\"] == \"mo\"][column].values[0]\n",
    "                < df_test_mo.loc[df_test_mo[\"source\"] == \"dept\"][column].values[0]\n",
    "            ):\n",
    "                mo_error.append(mo)\n",
    "                mo_error.append(column)\n",
    "                mo_error.append(\n",
    "                    df_test_mo.loc[df_test_mo[\"source\"] == \"mo\"][column].values[0]\n",
    "                )\n",
    "                mo_error.append(\n",
    "                    df_test_mo.loc[df_test_mo[\"source\"] == \"dept\"][column].values[0]\n",
    "                )\n",
    "mo_error_list = [mo_error[i : i + 4] for i in range(0, len(mo_error), 4)]\n",
    "df_mo_error = pd.DataFrame(\n",
    "    mo_error_list,\n",
    "    columns=[\n",
    "        \"id МО\",\n",
    "        \"наименование оборудования\",\n",
    "        \"непосредственно заявка МО\",\n",
    "        \"сумма заявок по СП\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# присоединение данных из исходного фрейма\n",
    "try:\n",
    "    df_mo_error = df_mo_error.merge(\n",
    "        df_ass_l, left_on=\"id МО\", right_on=\"ID\", how=\"left\"\n",
    "    )\n",
    "    df_mo_error = df_mo_error[\n",
    "        [\n",
    "            \"id МО\",\n",
    "            \"Регион\",\n",
    "            \"Наименование МО\",\n",
    "            \"наименование оборудования\",\n",
    "            \"непосредственно заявка МО\",\n",
    "            \"сумма заявок по СП\",\n",
    "        ]\n",
    "    ]\n",
    "except Exception:\n",
    "    print(\"Трабл при присоединении названия региона в ошибках МО\")\n",
    "\n",
    "# сохранение результата в файл\n",
    "if df_mo_error.empty:\n",
    "    print(\"Расхождений данных между МО и СП нет\")\n",
    "    df_mo_error = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"id МО\",\n",
    "            \"наименование оборудования\",\n",
    "            \"непосредственно заявка МО\",\n",
    "            \"сумма заявок по СП\",\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    df_mo_error.to_csv(\n",
    "        result_12_files_path + \"/несоответствие_МО-СП.csv\",\n",
    "        sep=\";\",\n",
    "        encoding=\"utf-8-sig\",\n",
    "        index=False,\n",
    "    )\n",
    "    print(\"Несоответствие между МО и СП сохранены в файл\")\n",
    "\n",
    "# проверка df_dept_result\n",
    "if df_dept_result.empty:\n",
    "    pass\n",
    "else:\n",
    "    dept_error = []\n",
    "    for mo in df_dept_result[\"id\"].unique():\n",
    "        df_test_dept = df_dept_result[df_dept_result[\"id\"] == mo]\n",
    "        # проверка на количество строк в df_test_dept\n",
    "        # если строк не 2, вся информация сохраняется в файл и проверка такого подразделения не осуществляется\n",
    "        if df_test_dept.shape[0] != 2 or len(df_test_dept[\"source\"].unique()) != 2:\n",
    "            path = result_12_files_path + \"/\" + mo + \"_dept.csv\"\n",
    "            df_test_dept.to_csv(path, sep=\";\", encoding=\"utf-8-sig\", index=False)\n",
    "        else:\n",
    "            for column in df_test_dept.columns[2:]:\n",
    "                if (\n",
    "                    df_test_dept.loc[df_test_dept[\"source\"] == \"room\"][column].values[0]\n",
    "                    > df_test_dept.loc[df_test_dept[\"source\"] == \"dept\"][column].values[\n",
    "                        0\n",
    "                    ]\n",
    "                ):\n",
    "                    dept_error.append(mo)\n",
    "                    dept_error.append(column)\n",
    "                    dept_error.append(\n",
    "                        df_test_dept.loc[df_test_dept[\"source\"] == \"dept\"][\n",
    "                            column\n",
    "                        ].values[0]\n",
    "                    )\n",
    "                    dept_error.append(\n",
    "                        df_test_dept.loc[df_test_dept[\"source\"] == \"room\"][\n",
    "                            column\n",
    "                        ].values[0]\n",
    "                    )\n",
    "                    # print(mo, column, df_test_dept.loc[df_test_dept['source']=='room'][column].values[0], df_test_dept.loc[df_test_dept['source']=='dept'][column].values[0])\n",
    "    dept_error_list = [dept_error[i : i + 4] for i in range(0, len(dept_error), 4)]\n",
    "    df_dept_error = pd.DataFrame(\n",
    "        dept_error_list,\n",
    "        columns=[\n",
    "            \"id СП\",\n",
    "            \"наименование оборудования\",\n",
    "            \"непосредственно заявка СП\",\n",
    "            \"сумма заявок по кабинетам\",\n",
    "        ],\n",
    "    )\n",
    "    try:\n",
    "        df_dept_error = df_dept_error.merge(\n",
    "            df_ass_l, left_on=\"id СП\", right_on=\"ID\", how=\"left\"\n",
    "        )\n",
    "        df_dept_error = df_dept_error[\n",
    "            [\n",
    "                \"id СП\",\n",
    "                \"Регион\",\n",
    "                \"Наименование МО\",\n",
    "                \"наименование оборудования\",\n",
    "                \"непосредственно заявка СП\",\n",
    "                \"сумма заявок по кабинетам\",\n",
    "            ]\n",
    "        ]\n",
    "    except Exception:\n",
    "        print(\"Трабл при присоединении названия региона в ошибках СП\")\n",
    "\n",
    "    # сохранение результата в файл\n",
    "    if df_dept_error.empty:\n",
    "        df_dept_error = pd.DataFrame(\n",
    "            columns=[\n",
    "                \"id СП\",\n",
    "                \"наименование оборудования\",\n",
    "                \"непосредственно заявка СП\",\n",
    "                \"сумма заявок по кабинетам\",\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        df_dept_error.to_csv(\n",
    "            result_12_files_path + \"/несоответствие_СП-кабинеты.csv\",\n",
    "            sep=\";\",\n",
    "            encoding=\"utf-8-sig\",\n",
    "            index=False,\n",
    "        )\n",
    "        print(\"Несоответствия между СП и кабинетами сохранены в файл\")\n",
    "\n",
    "# годная для дальнейшей работы структура фреймов с ошибками, если ошибок не было (котстыль)\n",
    "if df_dept_error.shape[0] == 0:\n",
    "    df_dept_error = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"id СП\",\n",
    "            \"Регион\",\n",
    "            \"наименование оборудования\",\n",
    "            \"непосредственно заявка СП\",\n",
    "            \"сумма заявок по кабинетам\",\n",
    "        ]\n",
    "    )\n",
    "if df_mo_error.shape[0] == 0:\n",
    "    df_mo_error = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"id МО\",\n",
    "            \"Регион\",\n",
    "            \"наименование оборудования\",\n",
    "            \"непосредственно заявка МО\",\n",
    "            \"сумма заявок по СП\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# проверка на заполненность данных - ищем регионы, которые не попросили вообще ничего\n",
    "# группировка и суммирование количества оборудования по регионам\n",
    "cols = [\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    4,\n",
    "    5,\n",
    "    6,\n",
    "    7,\n",
    "    8,\n",
    "]  # столбцы для удаления (иначе трабл с суммированием по ненужным столбцам, где есть и буквы, и цифры)\n",
    "df_ass_regions = df_ass.drop(df_ass.columns[cols], axis=1)\n",
    "df_ass_regions_sum = df_ass_regions.groupby(\"Регион\").sum().reset_index()\n",
    "# добавляем столбец с суммой заявок по регионам\n",
    "df_ass_regions_sum[\"region_sum\"] = df_ass_regions_sum[list(df_ass_regions_sum)[1:]].sum(\n",
    "    axis=1\n",
    ")\n",
    "# отбираем успешные и плохие регионы по сумме заявленного и формируем списки регионов\n",
    "df_ass_success_sum = df_ass_regions_sum[\n",
    "    df_ass_regions_sum[\"region_sum\"] != 0\n",
    "].reset_index()\n",
    "df_ass_erorr_sum = df_ass_regions_sum[\n",
    "    df_ass_regions_sum[\"region_sum\"] == 0\n",
    "].reset_index()\n",
    "bad_regions_sum_set = set(df_ass_erorr_sum[\"Регион\"].tolist())\n",
    "bad_regions_sum_list = list(bad_regions_sum_set)\n",
    "df_ass_erorr_sum = df_ass.loc[df_ass[\"Регион\"].isin(bad_regions_sum_list)]\n",
    "\n",
    "# проверка на заполненность данных 2 - ищем регионы с нулевым планом или нулевым фактом\n",
    "# удаляем непотребные столбцы\n",
    "cols = [\n",
    "    2,\n",
    "    3,\n",
    "    4,\n",
    "    5,\n",
    "    6,\n",
    "    7,\n",
    "    8,\n",
    "]  # столбцы для удаления (иначе трабл с суммированием по ненужным столбцам, где есть и буквы, и цифры)\n",
    "df_ass_mo_regions = df_ass.drop(df_ass.columns[cols], axis=1)\n",
    "# разделяем строки на \"план\" и \"факт\"\n",
    "# удаляем столбцы \"по факту\"\n",
    "del_columns_list_fact = []\n",
    "for col in df_ass_mo_regions.columns:\n",
    "    if col.split()[-1] == \"факту\":\n",
    "        del_columns_list_fact.append(col)\n",
    "df_ass_mo_plan = df_ass_mo_regions.drop(del_columns_list_fact, axis=1)\n",
    "# удаляем столбцы \"по плану\"\n",
    "del_columns_list_plan = []\n",
    "for col in df_ass_mo_regions.columns:\n",
    "    if col.split()[-1] == \"плану\":\n",
    "        del_columns_list_plan.append(col)\n",
    "df_ass_mo_fact = df_ass_mo_regions.drop(del_columns_list_plan, axis=1)\n",
    "# добавим столбцы с суммой плана и факта по каждой строке\n",
    "df_ass_mo_plan[\"count\"] = df_ass_mo_plan.iloc[:, 2:].sum(axis=1)\n",
    "df_ass_mo_fact[\"count\"] = df_ass_mo_fact.iloc[:, 2:].sum(axis=1)\n",
    "# отберём регионы с нулевым планом и нулевым фактом\n",
    "df_ass_mo_plan_zero = df_ass_mo_plan[df_ass_mo_plan[\"count\"] == 0]\n",
    "df_ass_mo_fact_zero = df_ass_mo_fact[df_ass_mo_fact[\"count\"] == 0]\n",
    "# плохие регионы по сумме плана\n",
    "bad_regions_sum_plan_set = set(df_ass_mo_plan_zero[\"Регион\"].tolist())\n",
    "bad_regions_sum_plan_list = list(bad_regions_sum_plan_set)\n",
    "# плохие регионы по сумме факта\n",
    "bad_regions_sum_fact_set = set(df_ass_mo_fact_zero[\"Регион\"].tolist())\n",
    "bad_regions_sum_fact_list = list(bad_regions_sum_set)\n",
    "# если есть плохие регионы по сумме плана и факта, выгрузим их в файл\n",
    "if df_ass_mo_plan_zero.empty:\n",
    "    print(\"Регионов с нулевым планом нет\")\n",
    "    bad_regions_sum_plan_set = set()\n",
    "else:\n",
    "    df_ass_mo_plan_zero.to_csv(\n",
    "        result_12_files_path + \"/пустая_сумма_плана.csv\",\n",
    "        sep=\";\",\n",
    "        encoding=\"utf-8-sig\",\n",
    "        index=False,\n",
    "    )\n",
    "    print(\"Данные по регионам с нулевой суммой плана сохранены в файл\")\n",
    "if df_ass_mo_fact_zero.empty:\n",
    "    print(\"Регионов с нулевым фактом нет\")\n",
    "    bad_regions_sum_fact_set = set()\n",
    "else:\n",
    "    df_ass_mo_fact_zero.to_csv(\n",
    "        result_12_files_path + \"/пустая_сумма_факта.csv\",\n",
    "        sep=\";\",\n",
    "        encoding=\"utf-8-sig\",\n",
    "        index=False,\n",
    "    )\n",
    "    print(\"Данные по регионам с нулевой суммой факта сохранены в файл\")\n",
    "\n",
    "# Антон велел убрать из успешных регионы с пустым планом ИЛИ пустой суммой. Но я это делать пока не буду, просто сохраню такие регионы\n",
    "bad_regions_plan_fact_set = bad_regions_sum_fact_set.union(\n",
    "    bad_regions_sum_plan_set\n",
    ")  # множество плохих регионов по нулевому плану ИЛИ нулевому факту - нигде не используется!\n",
    "\n",
    "# если плохие регионы есть, выгрузим их в файл\n",
    "if df_ass_erorr_sum.empty:\n",
    "    print(\"Регионов с полностью пустой заявкой нет\")\n",
    "else:\n",
    "    df_ass_erorr_sum.to_csv(\n",
    "        result_12_files_path + \"/пустая_сумма_заявок.csv\",\n",
    "        sep=\";\",\n",
    "        encoding=\"utf-8-sig\",\n",
    "        index=False,\n",
    "    )\n",
    "    print(\"Данные по регионам с нулевой суммой сохранены в файл\")\n",
    "\n",
    "# считаем ошибкой заявки ТОЛЬКО ПУСТОЙ ПЛАН: bad_regions_sum_plan_set\n",
    "# удаление из исходных данных проблемных регионов (и тех, у которых суммы не бьются, и тех, кто план не заполнил) и сохранение результата в файл\n",
    "try:\n",
    "    bad_mo_region_set = set(df_mo_error[\"Регион\"].tolist())\n",
    "except Exception:\n",
    "    bad_mo_region_set = set()\n",
    "    print(\"Ошибок МО нет\")\n",
    "try:\n",
    "    bad_dept_region_set = set(df_dept_error[\"Регион\"].tolist())\n",
    "except Exception:\n",
    "    bad_dept_region_set = set()\n",
    "    print(\"Ошибок СП нет\")\n",
    "\n",
    "# обьединяем все списики ошибочных регионов: ошибки сумм МО, ошибки сумм СП, регионы с нулевым планом\n",
    "bad_regions_list = list(\n",
    "    bad_mo_region_set.union(bad_dept_region_set).union(bad_regions_sum_plan_set)\n",
    ")\n",
    "df_ass_success = df_ass.loc[\n",
    "    ~df_ass[\"Регион\"].isin(bad_regions_list)\n",
    "]  # успешные регионы - которых нет в списке ошибочных\n",
    "df_ass_error = df_ass.loc[\n",
    "    df_ass[\"Регион\"].isin(bad_regions_list)\n",
    "]  # плохие регионы, которые есть в списке ошибочных\n",
    "df_ass_success.to_csv(\n",
    "    result_12_files_path + \"/успешные_регионы.csv\",\n",
    "    sep=\";\",\n",
    "    encoding=\"utf-8-sig\",\n",
    "    index=False,\n",
    ")\n",
    "print(\"Данные по успешным регионам сохранены в файл\")\n",
    "df_ass_error.to_csv(\n",
    "    result_12_files_path + \"/регионы_с_ошибками.csv\",\n",
    "    sep=\";\",\n",
    "    encoding=\"utf-8-sig\",\n",
    "    index=False,\n",
    ")\n",
    "print(\"Данные по регионам с ошибками сохранены в файл\")\n",
    "\n",
    "# архивирование\n",
    "zip_path = shutil.make_archive(result_12_files_path_arch, \"zip\", result_12_files_path)\n",
    "# удалнение папки с файлами ФЛК-1,2\n",
    "shutil.rmtree(result_12_files_path)\n",
    "print(\n",
    "    f\"Архив с файлами сохранён: {zip_path}, временная папка {result_12_files_path} удалена\"\n",
    ")\n",
    "\n",
    "# запись всего зоопарка в этот ваш excel\n",
    "\n",
    "# разъяснения для юзера\n",
    "df_notation = pd.DataFrame(\n",
    "    {\n",
    "        \"данные\": [\n",
    "            \"текущий статус\",\n",
    "            \"дата с... (включая)\",\n",
    "            \"дата по... (исключая)\",\n",
    "            \"исходник\",\n",
    "            \"фильтр дата-статус\",\n",
    "            \"регионы без ошибок\",\n",
    "            \"регионы с ошибками\",\n",
    "            \"несоответствие МО-СП\",\n",
    "            \"несоответствие СП-каб\",\n",
    "            \"пустая заявка\",\n",
    "            \"пустой план (ОШИБКА)\",\n",
    "            \"пустой факт (НЕ ошибка)\",\n",
    "            \"повторяющиеся МО\",\n",
    "        ],\n",
    "        \"содержание\": [\n",
    "            last_status,\n",
    "            last_status_date,\n",
    "            next_status_date,\n",
    "            \"исходные данные как они есть\",\n",
    "            \"исходные данные после применения фильтра по текущему статусу и дате последнего статуса\",\n",
    "            \"регионы, данные которых не содержат ошибок\",\n",
    "            \"регионы, в данных которых выявлены ошибки\",\n",
    "            \"данные по регионам, для которых количество заявленного оборудования в разрезе вида оборудования для МО мнее, чем суммарное количество заявленного оборудования в разрезе вида оборудования для СП, входящих в эту МО\",\n",
    "            \"аналогичные данные для несоответствия между количеством оборудования, заявленного для СП, и суммарным количеством оборудования, заявленного для кабинетов, входящих в это СП\",\n",
    "            \"данные по регионам, которые не указали вообще ничего (если есть хоть что-нибудь в любой позиции, регион сюда не попадёт) - это НЕ ошибка\",\n",
    "            \"данные по регионам, у которых в позициях плана ничего не заявлено - это ОШИБКА\",\n",
    "            \"данные по регионам, у которых в позициях факта ничего не заявлено - это НЕ ошибка\",\n",
    "            \"данные по МО, которые упоминаются в исходной выгрузке более одного раза (такого быть не должно). Данные по таким МО не обрабатываются, регион не попадает в ошибочные и что сним делать, должен решать аналитик\",\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "# создание Pandas Excel writer, используя XlsxWriter в качестве движка\n",
    "writer = pd.ExcelWriter(result_12_exc_path, engine=\"xlsxwriter\")\n",
    "\n",
    "# write each DataFrame to a specific sheet\n",
    "df_notation.to_excel(writer, sheet_name=\"о чём этот файл\", index=False)\n",
    "df_ass_0.to_excel(writer, sheet_name=\"исходник\", index=False)\n",
    "df_ass.to_excel(writer, sheet_name=\"фильтр дата-статус\", index=False)\n",
    "df_ass_success.to_excel(writer, sheet_name=\"регионы без ошибок\", index=False)\n",
    "df_ass_error.to_excel(writer, sheet_name=\"регионы с ошибками\", index=False)\n",
    "df_mo_error.to_excel(writer, sheet_name=\"несоответствие МО-СП\", index=False)\n",
    "df_dept_error.to_excel(writer, sheet_name=\"несоответствие СП-каб\", index=False)\n",
    "df_ass_erorr_sum.to_excel(writer, sheet_name=\"пустая заявка (не ошибка)\", index=False)\n",
    "df_ass_mo_plan_zero.to_excel(writer, sheet_name=\"пустой план (ошибка)\", index=False)\n",
    "df_ass_mo_fact_zero.to_excel(writer, sheet_name=\"пустой факт (не ошибка)\", index=False)\n",
    "df_mo_count_more_save.to_excel(writer, sheet_name=\"повторяющиеся МО\", index=False)\n",
    "\n",
    "# close the Pandas Excel writer and output the Excel file\n",
    "writer.close()\n",
    "print(\"Данные сохранены в файл Excel\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
