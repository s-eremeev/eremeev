{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e70a81dd-f8d1-498c-b35c-c15f82a376d8",
   "metadata": {},
   "source": [
    "# **Отчёт о выполнении работы по теме «Основы веб-скрапинга»**\n",
    "![](https://drive.google.com/uc?export=view&id=1hWGH-1bhAzCdMJwQbuXbqC6vAwkbLHVM)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb5f8443-83ea-430e-8a5f-5f78de6f7822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from lxml import html\n",
    "import time\n",
    "\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc2d048b-e6cd-466b-8dc7-34ff012a11f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba1c4d1-7de6-44e4-aec7-d671c7bad814",
   "metadata": {},
   "source": [
    "# **Доработанное задание**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686ae90a-2cd3-4987-8f79-d9d88f41cbab",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## **Обязательная часть**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1e1a2f-588e-47b6-8931-644cb19ad200",
   "metadata": {},
   "source": [
    "Вам необходимо написать функцию, которая будет основана на поиске по сайту [habr.com](https://habr.com/ru/search/). Функция в качестве параметра должна принимать список запросов для поиска (например, ['python', 'анализ данных']) и на основе материалов, попавших в результаты поиска по каждому запросу, возвращать датафрейм вида:\n",
    "\n",
    "><дата> - <заголовок> - <ссылка на материал>\n",
    "\n",
    "В рамках задания предполагается работа только с одной (первой) страницей результатов поисковой выдачи для каждого запроса. Материалы в датафрейме не должны дублироваться, если они попадали в результаты поиска для нескольких запросов из списка.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "456eb843-c7be-47a9-83b7-b3c57d2692d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_habr_megapost(requests_list):\n",
    "\n",
    "    \"\"\"Функция осуществляет поиск по сайту habr.com на основании списка запросов и возвращает первую страницу результатов поиска по каждому слову из списка.\n",
    "    Дубликаты найденных материалов удаляются\"\"\"\n",
    "\n",
    "    df_result = pd.DataFrame()\n",
    "    for search_query in requests_list:\n",
    "        response = requests.get(\n",
    "            \"https://habr.com/ru/search/\", params={\"q\": search_query}\n",
    "        )\n",
    "        soup = BeautifulSoup(response.text, \"html\")\n",
    "        find_ = soup.find_all(\"article\", class_=\"tm-articles-list__item\")\n",
    "        for el in find_:\n",
    "            try:\n",
    "                title = el.find(\n",
    "                    \"h2\",\n",
    "                    class_=\"tm-article-snippet__title tm-article-snippet__title_h2\",\n",
    "                ).text\n",
    "                link = el.find(\"a\", \"tm-article-snippet__title-link\").get(\"href\")\n",
    "                date = el.find(\n",
    "                    \"span\", \"tm-article-snippet__datetime-published\"\n",
    "                ).text.split(\" в \")[0]\n",
    "            except AttributeError:\n",
    "                title = el.find(\n",
    "                    \"a\", class_=\"tm-megapost-snippet__link tm-megapost-snippet__card\"\n",
    "                ).text\n",
    "                link = el.find(\n",
    "                    \"a\", \"tm-megapost-snippet__link tm-megapost-snippet__card\"\n",
    "                ).get(\"href\")\n",
    "                date = el.find(\n",
    "                    \"time\", \"tm-megapost-snippet__datetime-published\"\n",
    "                ).text.split(\" в \")[0]\n",
    "            row = {\"date\": date, \"title\": title, \"link\": \"https://habr.com\" + link}\n",
    "            df_result = pd.concat([df_result, pd.DataFrame([row])])\n",
    "        df_result = df_result.drop_duplicates().reset_index(drop=True)\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f2e62e7-aa7d-4584-ad09-58759fe9716a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=974f3564-7fea-4f43-9753-89dea536d2d5 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('974f3564-7fea-4f43-9753-89dea536d2d5').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20  января</td>\n",
       "      <td>Курс «Python для инженеров». Старт 3 потока 31 января</td>\n",
       "      <td>https://habr.com/ru/company/southbridge/news/t/646825/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13  декабря  2021</td>\n",
       "      <td>Жаждущим автоматизации: открытый урок «ChatOps c Errbot на Python», 21 декабря</td>\n",
       "      <td>https://habr.com/ru/company/southbridge/news/t/595093/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21  апреля  2020</td>\n",
       "      <td>Вышел Python 2.7.18, последний релиз ветки Python 2.x</td>\n",
       "      <td>https://habr.com/ru/news/t/498364/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6  июля  2021</td>\n",
       "      <td>Python Community Meetup 8/07: видео и материалы встречи</td>\n",
       "      <td>https://habr.com/ru/company/raiffeisenbank/news/t/566370/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13  января</td>\n",
       "      <td>Открытый урок «Пишем Custom Prometheus Exporter на Python», 19 января</td>\n",
       "      <td>https://habr.com/ru/company/southbridge/news/t/645485/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>17  сентября  2012</td>\n",
       "      <td>Паттерны проектирования (Head First Design Patterns)</td>\n",
       "      <td>https://habr.com/ru/company/piter/blog/151626/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>29  марта  2018</td>\n",
       "      <td>Книга «Head First. Паттерны проектирования. Обновленное юбилейное издание»</td>\n",
       "      <td>https://habr.com/ru/company/piter/blog/352202/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>18  июня  2021</td>\n",
       "      <td>Rust 1.53.0: IntoIterator для массивов, \"|\" в шаблонах, Unicode-идентификаторы, поддержка имени HEAD-ветки в Cargo</td>\n",
       "      <td>https://habr.com/ru/post/563548/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>22  ноября  2007</td>\n",
       "      <td>Firefox и HTTP HEAD метод</td>\n",
       "      <td>https://habr.com/ru/post/16539/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>28  июня  2016</td>\n",
       "      <td>Книга «Head First. Изучаем Ruby»</td>\n",
       "      <td>https://habr.com/ru/company/piter/blog/304212/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "                  date                                              title  \\\n",
       "0         20  января    Курс «Python для инженеров». Старт 3 потока 31...   \n",
       "1    13  декабря  2021  Жаждущим автоматизации: открытый урок «ChatOps...   \n",
       "2     21  апреля  2020  Вышел Python 2.7.18, последний релиз ветки Pyt...   \n",
       "3        6  июля  2021  Python Community Meetup 8/07: видео и материал...   \n",
       "4         13  января    Открытый урок «Пишем Custom Prometheus Exporte...   \n",
       "5          2  ноября    Самый полный стартовый гайд по ботам Telegram ...   \n",
       "6     4  декабря  2020  Python как компилируемый статически типизирова...   \n",
       "7           8  марта    Вышел мартовский релиз расширения Python для V...   \n",
       "8       3  марта  2020  В начале этого года Python сместил Java и стал...   \n",
       "9     16  ноября  2021  EPAM разработала бесплатный курс по программир...   \n",
       "10       19  августа    Осталась неделя до старта 4 потока Python для ...   \n",
       "11       3  июня  2020  Вышла версия 0.0.2 snakeware — дистрибутива Li...   \n",
       "12    13  ноября  2020  Создатель Python Гвидо ван Россум выходит на р...   \n",
       "13       25  октября                                    Вышел Python 3.11   \n",
       "14   31  октября  2019  Создатель Python Гвидо ван Россум ушел из Drop...   \n",
       "15    6  октября  2021          Вышел язык программирования Python 3.10.0   \n",
       "16   11  октября  2021  Python вышел на первое место рейтинга TIOBE, и...   \n",
       "17           3  июня    «Тестирование веб-приложений на Python» — новы...   \n",
       "18       24  августа    Python, SQL, С и Java стали самыми популярными...   \n",
       "19  16  сентября  2020  Астрономам порекомендовали меньше использовать...   \n",
       "20   25  декабря  2017  Новый подход к спортивному анализу данных: как...   \n",
       "21  28  сентября  2018  Приглашаем на Sberbank Data Science Journey 20...   \n",
       "22     9  ноября  2018  Прямая трансляция Sberbank Data Science Day 10...   \n",
       "23   28  декабря  2016  Отчёт со Sberbank Data Science Day: решения, п...   \n",
       "24     7  ноября  2017  Приглашаем на Sberbank Data Science Day 11 ноября   \n",
       "25      14  июля  2021             Поприветствуйте компонент Inertia Head   \n",
       "26      23  июня  2021                    Что можно положить в тег <head>   \n",
       "27       2  июля  2015                    Head Unit — как цель для хакера   \n",
       "28      23  июля  2014  Head-Up Display для любой машины — как ездить ...   \n",
       "29    18  ноября  2014  Разбор Heads-up Display из горнолыжной маски R...   \n",
       "30    23  января  2021  Компания T-Head собрала порт Android 10 для пр...   \n",
       "31        23  апреля    Джек Дорси вместо гендиректора (CEO Block) ста...   \n",
       "32    7  октября  2016  Универсальний (изоморфный) «шлем» для React js...   \n",
       "33   11  февраля  2016   Книга «Head First. Программирование для Android»   \n",
       "34    1  февраля  2021     Coins classifier Neural Network: Head or Tail?   \n",
       "35           8  июля    Мой путь до Head of Backend, или как я учусь б...   \n",
       "36     11  марта  2021  Оживление портрета с помощью Realistic Neural ...   \n",
       "37   4  сентября  2014     Распродажа книг из серии «Head First O'Reilly»   \n",
       "38  29  сентября  2021  Книга «Head First. Паттерны проектирования. 2-...   \n",
       "39         5  апреля             Книга «Head First. Изучаем C#. 4-е изд.»   \n",
       "40  17  сентября  2012  Паттерны проектирования (Head First Design Pat...   \n",
       "41     29  марта  2018  Книга «Head First. Паттерны проектирования. Об...   \n",
       "42      18  июня  2021  Rust 1.53.0: IntoIterator для массивов, \"|\" в ...   \n",
       "43    22  ноября  2007                          Firefox и HTTP HEAD метод   \n",
       "44      28  июня  2016                   Книга «Head First. Изучаем Ruby»   \n",
       "\n",
       "                                                 link  \n",
       "0   https://habr.com/ru/company/southbridge/news/t...  \n",
       "1   https://habr.com/ru/company/southbridge/news/t...  \n",
       "2                  https://habr.com/ru/news/t/498364/  \n",
       "3   https://habr.com/ru/company/raiffeisenbank/new...  \n",
       "4   https://habr.com/ru/company/southbridge/news/t...  \n",
       "5                    https://habr.com/ru/post/697052/  \n",
       "6                  https://habr.com/ru/news/t/531402/  \n",
       "7                  https://habr.com/ru/news/t/654707/  \n",
       "8   https://habr.com/ru/company/itsumma/news/t/490...  \n",
       "9   https://habr.com/ru/company/epam_systems/news/...  \n",
       "10  https://habr.com/ru/company/southbridge/news/t...  \n",
       "11                 https://habr.com/ru/news/t/505096/  \n",
       "12                 https://habr.com/ru/news/t/527858/  \n",
       "13                 https://habr.com/ru/news/t/695298/  \n",
       "14                 https://habr.com/ru/news/t/473926/  \n",
       "15                 https://habr.com/ru/news/t/581862/  \n",
       "16                 https://habr.com/ru/news/t/582682/  \n",
       "17  https://habr.com/ru/company/yandex_praktikum/n...  \n",
       "18                 https://habr.com/ru/news/t/684376/  \n",
       "19                 https://habr.com/ru/news/t/519414/  \n",
       "20                https://habr.com/ru/article/344806/  \n",
       "21  https://habr.com/ru/company/sberbank/blog/424635/  \n",
       "22  https://habr.com/ru/company/sberbank/blog/429320/  \n",
       "23                https://habr.com/ru/article/318160/  \n",
       "24  https://habr.com/ru/company/sberbank/blog/341814/  \n",
       "25      https://habr.com/ru/company/otus/blog/567718/  \n",
       "26  https://habr.com/ru/company/htmlacademy/blog/5...  \n",
       "27                   https://habr.com/ru/post/257287/  \n",
       "28                   https://habr.com/ru/post/230859/  \n",
       "29                   https://habr.com/ru/post/243465/  \n",
       "30  https://habr.com/ru/company/itsumma/news/t/538...  \n",
       "31                 https://habr.com/ru/news/t/662564/  \n",
       "32                   https://habr.com/ru/post/311964/  \n",
       "33     https://habr.com/ru/company/piter/blog/277023/  \n",
       "34                   https://habr.com/ru/post/540324/  \n",
       "35  https://habr.com/ru/company/scalablesolutions/...  \n",
       "36                   https://habr.com/ru/post/494678/  \n",
       "37     https://habr.com/ru/company/piter/blog/235627/  \n",
       "38     https://habr.com/ru/company/piter/blog/580670/  \n",
       "39     https://habr.com/ru/company/piter/blog/656137/  \n",
       "40     https://habr.com/ru/company/piter/blog/151626/  \n",
       "41     https://habr.com/ru/company/piter/blog/352202/  \n",
       "42                   https://habr.com/ru/post/563548/  \n",
       "43                    https://habr.com/ru/post/16539/  \n",
       "44     https://habr.com/ru/company/piter/blog/304212/  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests_list = [\"python\", \"SDSJ\", \"head\"]\n",
    "search_habr_megapost(requests_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7865a27b-e7ea-4317-9a82-e76dadcccf4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "242ade50-cbe3-44a0-9d26-19401595bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mitosheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228f4f7f-0b99-4622-8408-a3434ace5a43",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## **Дополнительная часть (необязательная)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28ed8d8-fe37-485f-87d8-27e4cd2a87d9",
   "metadata": {},
   "source": [
    "Функция из обязательной части задания должна быть расширена следующим образом:\n",
    "\n",
    "- кроме списка ключевых слов для поиска необходимо объявить параметр с количеством страниц поисковой выдачи. Т.е. при передаче в функцию аргумента 4 необходимо получить материалы с первых 4 страниц результатов;\n",
    "- в датафрейме должны быть столбцы с полным текстом найденных материалов и количеством лайков:\n",
    "> <дата> - <заголовок> - <ссылка на материал> - <текст материала> - <количество лайков>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba0ce7e-38ab-4175-b52e-442fcf26a907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_habr_full(requests_list, page_count):\n",
    "\n",
    "    \"\"\"Функция осуществляет поиск по сайту habr.com на основании списка запросов и возвращает указанное число страниц\"\"\"\n",
    "\n",
    "    df_result = pd.DataFrame()\n",
    "    for search_query in requests_list:\n",
    "        for page in range(1, page_count + 1):\n",
    "            url = \"https://habr.com/ru/search/page\" + str(page) + \"/\"\n",
    "            params = {\"q\": search_query}\n",
    "            response = requests.get(url, params=params)\n",
    "            time.sleep(0.33)\n",
    "            soup = BeautifulSoup(response.text, \"html\")\n",
    "            find_ = soup.find_all(\"article\", class_=\"tm-articles-list__item\")\n",
    "            df_page_result = pd.DataFrame()\n",
    "            for el in find_:\n",
    "                # здесь название, ссылка и \"дата\" в виде текста, это работает\n",
    "                try:\n",
    "                    title = el.find(\n",
    "                        \"h2\",\n",
    "                        class_=\"tm-article-snippet__title tm-article-snippet__title_h2\",\n",
    "                    ).text\n",
    "                    link = el.find(\"a\", \"tm-article-snippet__title-link\").get(\"href\")\n",
    "                    date = el.find(\n",
    "                        \"span\", \"tm-article-snippet__datetime-published\"\n",
    "                    ).text.split(\" в \")[0]\n",
    "                except AttributeError:\n",
    "                    title = el.find(\n",
    "                        \"a\",\n",
    "                        class_=\"tm-megapost-snippet__link tm-megapost-snippet__card\",\n",
    "                    ).text\n",
    "                    link = el.find(\n",
    "                        \"a\", \"tm-megapost-snippet__link tm-megapost-snippet__card\"\n",
    "                    ).get(\"href\")\n",
    "                    date = el.find(\n",
    "                        \"time\", \"tm-megapost-snippet__datetime-published\"\n",
    "                    ).text.split(\" в \")[0]\n",
    "                # здесь лайки. class лайков зависит от качественной характеристики оценки, перебираем возмождные варианты\n",
    "                for element_class in [\n",
    "                    \" \",\n",
    "                    \" tm-votes-meter__value_positive \",\n",
    "                    \" tm-votes-meter__value_negative \",\n",
    "                ]:\n",
    "                    class_ = (\n",
    "                        \"tm-votes-meter__value tm-votes-meter__value\"\n",
    "                        + element_class\n",
    "                        + \"tm-votes-meter__value_appearance-article tm-votes-meter__value_rating\"\n",
    "                    )\n",
    "                    try:\n",
    "                        likes = el.find(\"span\", class_=class_).text\n",
    "                        break\n",
    "                    except AttributeError:\n",
    "                        pass\n",
    "                # здесь заканчиваем разбирать лайки и приступаем к поиску полного текста поста по ранее найденной ссылке\n",
    "                req = requests.get(\"https://habr.com\" + link).text\n",
    "                soup_full_text = BeautifulSoup(req)\n",
    "                # здесь перебираем номера версий для постов. Вообще-то версий, если проверять вручную, всего 2, но, для надёжности, сделаем больше\n",
    "                version = 1\n",
    "                while version <= 10:\n",
    "                    try:\n",
    "                        class_ = (\n",
    "                            \"article-formatted-body article-formatted-body article-formatted-body_version-\"\n",
    "                            + str(version)\n",
    "                        )\n",
    "                        full_text = soup_full_text.find(\n",
    "                            \"div\", class_=class_\n",
    "                        ).text.strip()\n",
    "                        full_text = re.sub(r\"\\s+\", \" \", full_text)\n",
    "                        break\n",
    "                    except AttributeError:\n",
    "                        version += 1\n",
    "                        full_text = \"megapost\"\n",
    "                # здесь неуклюже вытаскиваем полный текст из этиго вашего megapost'a\n",
    "                if full_text == \"megapost\":\n",
    "                    resp = requests.get(\"https://habr.com\" + link)\n",
    "                    soup = BeautifulSoup(resp.text, \"html\")\n",
    "                    find_title_text = soup.find_all(\n",
    "                        \"div\", class_=\"t119__preface t-descr t-opacity_70\"\n",
    "                    )\n",
    "                    find_text = soup.find_all(\"div\", class_=\"t-text t-text_md\")\n",
    "                    full_text = \"\"\n",
    "                    try:\n",
    "                        i = 0\n",
    "                        while True:\n",
    "                            full_text += find_title_text[i].text\n",
    "                            i += 1\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "                    try:\n",
    "                        j = 0\n",
    "                        while True:\n",
    "                            full_text += find_text[j].text\n",
    "                            j += 1\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "                # разобрались со всеми данными, формируем страницу\n",
    "                row = {\n",
    "                    \"date\": date,\n",
    "                    \"title\": title,\n",
    "                    \"link\": \"https://habr.com\" + link,\n",
    "                    \"text\": full_text,\n",
    "                    \"likes\": likes,\n",
    "                }\n",
    "                df_page_result = pd.concat([df_page_result, pd.DataFrame([row])])\n",
    "                df_page_result = df_page_result.drop_duplicates()\n",
    "                # присоединяем страницу к ранее найденному\n",
    "                df_result = pd.concat([df_result, df_page_result])\n",
    "    # объединяем найденное и возаращаем результат поиска\n",
    "    return df_result.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfa8d90b-fce5-4de9-99b4-559949bd67f3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=27c0e28a-7b79-4f02-8c15-42cd6a32b6d8 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('27c0e28a-7b79-4f02-8c15-42cd6a32b6d8').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25  октября  2021</td>\n",
       "      <td>Ошибка в экспоненциальной форме записи чисел в MySQL сделала клиентов AWS WAF уязвимыми для внедрения SQL</td>\n",
       "      <td>https://habr.com/ru/news/t/585346/</td>\n",
       "      <td>Этичные хакеры из Go Secure обнаружили ошибку в MySQL, угрожающую безопасности. Из-за неё клиенты AWS Web Application Firewall (WAF) остались незащищёнными от внедрения SQL. Ещё одна исследовательская группа дополнительно подтвердила, что это влияет на безопасность, и предоставила один из способов, как исправить эту ошибку.В 2013 году в презентации BlackHat под названием «Методы оптимизации и обфуксации SQL» Роберто Сальгадо представил несколько методов обхода для SQL-внедрения. Доклад включал методы для MySQL и MariaDB. В 2018 году хакеры из GoSecure пересмотрели эту презентацию и начали проводить тесты с MySQL и MariaDB. Они обнаружили, что ошибка экспоненциальной формы записи чисел, упомянутая в презентации Сальгадо, имела более широкие последствия. Оказывается, с её помощью можно добиться интересных вещей – интересных с точки взломщика. Эта ошибка позволяет синтаксису SQL оставаться рабочим, даже если он не должен быть таковым, что сбивает с толку средства защиты.Экспоненциальная форма записи чисел (далее экспоненциальная запись) и, в частности, функция «e», была интегрирована во многие языки программирования, включая SQL. Неясно, является ли это частью всех реализаций SQL, но это часть реализации MySQL/MariaDB. Вот пример экспоненциальной записи, интегрированной в SQL-запрос из той самой презентации Роберто Сальгадо 2013 года. Обозначение «e» будет проигнорировано, поскольку оно используется в недопустимом контексте:SELECT table_name FROM information_schema 1.e.tablesТаким образом, предыдущий запрос будет вести себя так же, как:SELECT table_name FROM information_schema .tablesС помощью пары тестов обнаружено, что после команды «1.e» можно использовать следующие символы:( ) . , | &amp; % * ^ /Чтобы проиллюстрировать проблему, авторы обзора привели пример набора данных:Чего можно достичь с помощью команды «1.e» и символов за ней:Приведённый выше запрос равен следующему запросу:Примечательно, что цифра или число в команде «1.e» значения не имеет. Между точкой и функцией «е» может быть любое число или любой набор цифр, но точка является обязательной (например, «1337.1337e» также работает). AWS — продукт CloudFront, который можно комбинировать с AWS WAF с определенными правилами. Они помогают компаниям защитить свои веб-приложения от взлома. Однако во время взаимодействия авторы обнаружили, что правило «База данных SQL» в AWS WAF можно обойти с помощью ошибки, указанной выше.Простой запрос может показать, что WAF блокирует запрос с помощью известной команды 1′ или ′1′=′1:Если использовать экспоненциальную запись в этом простом запросе, получится следующее:Одного такого доказательства достаточно, чтобы объяснить, почему и как работает эта ошибка и продемонстрировать уязвимость безопасности для всех заинтересованных лиц.Сначала ошибку в MySQL и MariaDB проигнорировали, так как никто не увидел последствий. Это никак не влияло на данные и не позволило повышать права, пока не нашелся обход WAF. Теперь, когда есть уязвимость в безопасности, можно выяснить, почему появилась такая ошибка и из-за чего она так себя ведет.Во-первых, MySQL и MariaDB работают, находя признаки в запросе, такие как: числа, строки, комментарии, конец строки и т. д. Как только признак распознан, нужная функция анализирует его.Во-вторых, кусок рассматриваемого кода проверяет целые или вещественные числа, поскольку сначала работает этот сегмент:В-третьих, сегмент кода находит точку и попадает в функцию действительных чисел, и это тот сегмент, который нужен для понимания ошибки:В этот момент сегмент кода уже обработал цифры перед точкой и начинает обрабатывать все цифры после точки. Потом условие проверяет, является ли символ буквой «e» или «E» и переходит к следующему символу. Если следующий за «е» символ не является цифрой, состояние устанавливается в «MY_LEX_CHAR», а затем завершается оператором «break», который возвращается в начало варианта переключения.Наконец, следующим сегментом кода достигнут нужный оператор, и здесь признак полностью забывается и удаляется из запроса:Как видно из примера, оператор «MY_LEX_CHAR» идёт через оператор «MY_LEX_SKIP», потому что, как можно понять из комментария «Unknown or single char token» (то есть неизвестный признак или символ) MySQL просто не знает, что с этим делать в данный момент. В случае с оператором «MY_LEX_SKIP» всё завершается возвратом символа. Если символ не является закрывающей круглой скобкой - «)», то переходим к оператору «MY_LEX_START», который будет искать новый признак. В любом случае, даже если он заканчивается закрытой скобкой, всё равно признак не возвращается, а отбрасывается.Для исправления ошибки достаточно было бы прервать запрос, если признак неверен, вместо того, чтобы его пропустить. Когда MySQL или MariaDB находят начало признака с плавающей запятой и что за ним не идет цифра, они должен прервать запрос.Хакеры отправили исправление в проекты MySQL и MariaDB. В данном случае это не проблема безопасности в MySQL/MariaDB как таковая. Любой WAF или аналогичные продукты игнорируют запросы SQL, сформированные таким образом, поэтому уязвимы. Если запросы в неправильном формате, продукты безопасности не будут рассматривать их как действительный код SQL и просто проигнорируют. Поэтому представленное исправление должно увеличить шансы на быстрое решение.Позже хакеры решили оценить ModSecurity, популярный WAF для Apache и nginx. Он включает в себя библиотеку libinjection, на которую влияет представленная ошибка.Ниже демонстрация возможности modsecurity блокировать вредоносный шаблон для SQL-внедрения. Возвращается запрещённая страница, что является следствием обнаружения.Записи из modsecurity, в которых подчеркивается, что библиотека libinjection была запущена:Обойти эту защиту можно, поставив перед буквальным выражением экспоненциальную запись «1.e». Библиотека Libinjection маркирует этот признак и определяет типы контекстных разделов как в предыдущем случае: комментарии и строки.Libinjection рассматривает строку «1.e» как неизвестную команду SQL и приходит к выводу, что это скорее часть текста, чем часть кода. Такое поведение библиотеки libinjection возможно, когда она встречает неизвестную функции SQL. OWASP Core Rule Set (CRS) указали, что эффективная защита доступна ModSecurity, если установлен уровень в классификации ModSecurity «paranoia level 2». В нём есть функционал к обнаружению скрытых атак.Эта проблема безопасности не похожа на многие другие, так как она может быть легко преуменьшена до простой ошибки синтаксического анализатора. AWS понял риск и решил исправить это в своём WAF, тем более, что это ситуация оставляла клиентов Amazon незащищёнными. Есть надежда, что в перспективе MySQL и MariaDB исправят ошибку, и через десяток лет метод исправления, показанный в данной статье, не понадобится.</td>\n",
       "      <td>+25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7  апреля</td>\n",
       "      <td>Яндекс Практикум запускает курс «SQL для работы с данными и аналитики»</td>\n",
       "      <td>https://habr.com/ru/company/yandex_praktikum/news/t/659427/</td>\n",
       "      <td>Яндекс Практикум разработал курс «SQL для работы с данными и аналитики». За полтора месяца студенты с нуля пройдут путь от новичка до уверенного пользователя SQL. Программа предназначена для начинающих и продолжающих обучение аналитиков, продакт- и проджект-менеджеров, специалистов техподдержки, UX-исследователей и новичков, которые хотят составлять SQL-запросы и работать с СУБД, даже если у них нет опыта в базах данных и html. Выпускники получат удостоверение о повышении квалификации. Чему вы научитесь на курсе Проводить маркетинговые исследования, чтобы оценить успешность бизнеса или продукта. Находить и отфильтровывать данные при помощи SQL-запросов. Рассчитывать продуктовые метрики, чтобы сравнивать товары и услуги. Хранить, обрабатывать и управлять данными в СУБД. Как проходит обучение Курс занимает 1,5 месяца. Обучение построено так, чтобы сразу отрабатывать полученные знания на практике. Основная часть: теория и SQL-тренажёр. Учебный материал разбит на два блока: базовый SQL и продвинутый SQL. Каждый из блоков представлен в двух форматах: текст и видеоуроки. Каждый теоретический блок сразу закрепляется на практике — в SQL-тренажёре. Все задания представляют из себя именно то, с чем можно столкнуться в реальных рабочих ситуациях. Еженедельные вебинары с наставником. На вебинарах студенты смогут задать любые вопросы, связанные как с решением учебных задач, так и с тем, с чем они столкнулись в своих реальных рабочих процессах. Курсовые проекты. По итогам прохождения каждого из двух блоков студенты выполнят бизнес-проект на основе требований заказчиков. Дополнительная теория и практика в SQL-тренажёре. Помимо основной программы, на курсе есть дополнительный блок теории, который поможет больше узнать о базах данных и их применении, а также освоить дополнительные инструменты и возможности SQL. В тренажёре есть задачи разной сложности. Их можно решать в свободном режиме, сравнивать свои решения с эталонными и исправлять, если допустили ошибку. В ходе обучения студентов сопровождают наставники, кураторы и служба поддержки. Выпускники станут частью комьюнити, которое объединяет специалистов и единомышленников с экспертизой в разных областях. Вместе с сообществом вы сможете обмениваться опытом, разбирать сложные задачи и помогать друг другу в учёбе. Подробности Курс длится 1,5 месяца. Для успешного прохождения мы рекомендуем уделять обучению 8-10 часов в неделю. На курсе есть бесплатная вводная часть: вы можете выполнить несколько заданий в SQL-тренажёре, примерить процесс обучения на себя и после этого принять решение. Ознакомиться с программой и записаться на курс можно на сайте.</td>\n",
       "      <td>+2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30  июня  2021</td>\n",
       "      <td>Решения Quest для управления и мониторинга Microsoft SQL Server — анонс вебинара</td>\n",
       "      <td>https://habr.com/ru/company/galssoftware/news/t/565380/</td>\n",
       "      <td></td>\n",
       "      <td>+3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24  августа</td>\n",
       "      <td>Python, SQL, С и Java стали самыми популярными языками программирования в ежегодном рейтинге IEEE Spectrum</td>\n",
       "      <td>https://habr.com/ru/news/t/684376/</td>\n",
       "      <td>Американский журнал IEEE Spectrum опубликовал ежегодный рейтинг языков программирования. Для оценки относительной популярности разных языков рейтинг учитывает несколько показателей из разных источников, таких как GitHub, Google, Stack Overflow, Twitter и IEEE Xplore. Всего было составлено три рейтинга с упором на различные ключевые факторы. Самыми популярными языками в этих рейтингах стали Python, SQL, С и Java. Первый рейтинг Spectrum ориентирован на предпочтения и профессиональное мнение инженеров IEEE (Института инженеров электротехники и электроники). Здесь в пятёрку лучших входят Python, C, C++, C# и Java. При этом журнал отмечает, что совокупная популярность C и больших C-подобных языков намного превосходит Python. В пятёрку наименее популярных языков в этом рейтинге попали: Elm, Raku, WebAssembly, CoffeeScript, Eiffel.Рейтинг Jobs ориентируется на данные с сайта вакансий IEEE и CareerBuilder. В этом рейтинге в пятёрке лучших находятся SQL, Java, Python, JavaScript и С#. Нижние пять строчек занимают Raku, Eiffel, F#, J, D.Просмотрев сотни вакансий, аналитики пришли к выводу, что лидерство SQL заключается не в том, что многие работодатели ищут только программистов SQL. Как правило, работодателям нужно знание какого-то определённого языка вместе с SQL. Таким образом, IEEE отмечает, что знание SQL может стать «очень ценной стрелой в колчане». Третий рейтинг Trending основан на показателях роста популярности, и в нём снова лидирует Python. Кроме него в пятёрке самых популярных оказались Java, C, JavaScript и C++. Нижние пять строчек занимают TLC, Elm, WebAssembly, CoffeeScript и Eiffel.В середине августа этого года TIOBE Software представила свой рейтинг самых популярных языков программирования. По сравнению с прошлым годом Python прибавил в популярности 3,56%, переместившись со второго на первое место с показателем 15,42%. Это самый высокий показатель популярности данного языка программирования за всё время существования рейтинга. Самый низкий был зафиксирован в 2003 году (0,97%), когда Pyhton занимал 13-е место в рейтинге.</td>\n",
       "      <td>+3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30  октября</td>\n",
       "      <td>Топ полезных SQL-запросов для PostgreSQL</td>\n",
       "      <td>https://habr.com/ru/post/696274/</td>\n",
       "      <td>Статей о работе с PostgreSQL и её преимуществах достаточно много, но не всегда из них понятно, как следить за состоянием базы и метриками, влияющими на её оптимальную работу. В статье подробно рассмотрим SQL-запросы, которые помогут вам отслеживать эти показатели и просто могут быть полезны как пользователю.Зачем следить за состоянием PostgreSQL?Мониторинг базы данных также важен, как и мониторинг ваших приложений. Необходимо отслеживать процессы более детализировано, чем на системном уровне. Для этого можно отслеживать следующие метрики:Насколько эффективен кэш базы данных?Какой размер таблиц в вашей БД?Используются ли ваши индексы?И так далее.Мониторинг размера БД и её элементов1. Размер табличных пространствSELECT spcname, pg_size_pretty(pg_tablespace_size(spcname)) FROM pg_tablespace WHERE spcname&lt;&gt;'pg_global';После запуска запроса вы получите информацию о размере всех tablespace созданных в вашей БД. Функция pg_tablespace_size предоставляет информацию о размере tablespace в байтах, поэтому для приведения к читаемому виду мы также используем функцию pg_size_pretty. Пространство pg_global исключаем, так как оно используется для общих системных каталогов.2. Размер баз данныхSELECT pg_database.datname, pg_size_pretty(pg_database_size(pg_database.datname)) AS size FROM pg_database ORDER BY pg_database_size(pg_database.datname) DESC;После запуска запроса вы получите информацию о размере всех баз данных, созданных в рамках вашего экземпляра PostgreSQL.3. Размер схем в базе данныхSELECT A.schemaname, pg_size_pretty (SUM(pg_relation_size(C.oid))) as table, pg_size_pretty (SUM(pg_total_relation_size(C.oid)-pg_relation_size(C.oid))) as index, pg_size_pretty (SUM(pg_total_relation_size(C.oid))) as table_index, SUM(n_live_tup) FROM pg_class C LEFT JOIN pg_namespace N ON (N.oid = C .relnamespace) INNER JOIN pg_stat_user_tables A ON C.relname = A.relname WHERE nspname NOT IN ('pg_catalog', 'information_schema') AND C .relkind &lt;&gt; 'i' AND nspname !~ '^pg_toast' GROUP BY A.schemaname;После запуска запроса вы получите детальную информацию о каждой схеме в вашей базе данных: суммарный размер всех таблиц, суммарный размер всех индексов, общий суммарный размер схемы и суммарное количество строк во всех таблицах схемы.4. Размер таблицSELECT schemaname, C.relname AS \"relation\", pg_size_pretty (pg_relation_size(C.oid)) as table, pg_size_pretty (pg_total_relation_size (C.oid)-pg_relation_size(C.oid)) as index, pg_size_pretty (pg_total_relation_size (C.oid)) as table_index, n_live_tup FROM pg_class C LEFT JOIN pg_namespace N ON (N.oid = C .relnamespace) LEFT JOIN pg_stat_user_tables A ON C.relname = A.relname WHERE nspname NOT IN ('pg_catalog', 'information_schema') AND C.relkind &lt;&gt; 'i' AND nspname !~ '^pg_toast' ORDER BY pg_total_relation_size (C.oid) DESCПосле запуска запроса вы получите детальную информацию о каждой таблице с указанием её схемы, размера без индексов, размере индексов, суммарном размере таблицы и индексов, а также количестве строк в таблице.Контроль блокировокЕсли вашей базой данных пользуется большего одного пользователя, то всегда есть риск взаимной блокировки запросов и появления очереди с большим количеством запросов, которые будут находиться в ожидание. Чаще всего такое может возникнуть при обработке большого количества запросов, использующих одинаковые таблицы. Они будут мешать завершиться друг другу и не давать запуститься другим запросам. Больше об этом можно прочитать в официальной документации. Мы же рассмотрим способы нахождения блокировок и их снятия.1. Мониторинг блокировокSELECT COALESCE(blockingl.relation::regclass::text, blockingl.locktype) AS locked_item, now() - blockeda.query_start AS waiting_duration, blockeda.pid AS blocked_pid, blockeda.query AS blocked_query, blockedl.mode AS blocked_mode, blockinga.pid AS blocking_pid, blockinga.query AS blocking_query, blockingl.mode AS blocking_mode FROM pg_locks blockedl JOIN pg_stat_activity blockeda ON blockedl.pid = blockeda.pid JOIN pg_locks blockingl ON (blockingl.transactionid = blockedl.transactionid OR blockingl.relation = blockedl.relation AND blockingl.locktype = blockedl.locktype) AND blockedl.pid &lt;&gt; blockingl.pid JOIN pg_stat_activity blockinga ON blockingl.pid = blockinga.pid AND blockinga.datid = blockeda.datid WHERE NOT blockedl.granted AND blockinga.datname = current_database();Данный запрос показывает всю информацию о заблокированных запросах, а также информацию о том, кем они заблокированы.2. Снятие блокировокSELECT pg_cancel_backend(PID_ID); OR SELECT pg_terminate_backend(PID_ID);PID_ID - это ID запроса, который блокирует другие запросы. Чаще всего хватает отмены одного блокирующего запроса, чтобы снять блокировки и запустить всю накопившуюся очередь. Разница между pg_cancel_backend и pg_terminate_backend в том, что pg_cancel_backend отменяет запрос, а pg_terminate_backend завершает сеанс и, соответственно, закрывает подключение к базе данных. Команда pg_cancel_backend более щадящая и в большинстве случаев вам её хватит. Если нет, используем pg_terminate_backend. Показатели оптимальной работы вашей БД1. Коэффициент кэширования (Cache Hit Ratio)SELECT sum(heap_blks_read) as heap_read, sum(heap_blks_hit) as heap_hit, sum(heap_blks_hit) / (sum(heap_blks_hit) + sum(heap_blks_read)) as ratio FROM pg_statio_user_tables; Коэффициент кэширования - это показатель эффективности чтения, измеряемый долей операций чтения из кэша по сравнению с общим количеством операций чтения как с диска, так и из кэша. За исключением случаев использования хранилища данных, идеальный коэффициент кэширования составляет 99% или выше, что означает, что по крайней мере 99% операций чтения выполняются из кэша и не более 1% - с диска.2. Использование индексовSELECT relname, 100 * idx_scan / (seq_scan + idx_scan) percent_of_times_index_used, n_live_tup rows_in_table FROM pg_stat_user_tables WHERE seq_scan + idx_scan &gt; 0 ORDER BY n_live_tup DESC;Добавление индексов в вашу базу данных имеет большое значение для производительности запросов. Индексы особенно важны для больших таблиц. Этот запрос показывает количество строк в таблицах и процент времени использования индексов по сравнению с чтением без индексов. Идеальные кандидаты для добавления индекса - это таблицы размером более 10000 строк с нулевым или низким использованием индекса.3. Коэффициент кэширования индексов (Index Cache Hit Rate)SELECT sum(idx_blks_read) as idx_read, sum(idx_blks_hit) as idx_hit, (sum(idx_blks_hit) - sum(idx_blks_read)) / sum(idx_blks_hit) as ratio FROM pg_statio_user_indexes;Данный коэффициент похож на обычный коэффициент кэширования, но рассчитывается на данных использования индексов.4. Неиспользуемые индексыSELECT schemaname, relname, indexrelname FROM pg_stat_all_indexes WHERE idx_scan = 0 and schemaname &lt;&gt; 'pg_toast' and schemaname &lt;&gt; 'pg_catalog'Данный запрос находит индексы, которые созданы, но не использовались в SQL-запросах.5. Раздувание базы данных (Database bloat)SELECT current_database(), schemaname, tablename, /*reltuples::bigint, relpages::bigint, otta,*/ ROUND((CASE WHEN otta=0 THEN 0.0 ELSE sml.relpages::float/otta END)::numeric,1) AS tbloat, CASE WHEN relpages &lt; otta THEN 0 ELSE bs*(sml.relpages-otta)::BIGINT END AS wastedbytes, iname, /*ituples::bigint, ipages::bigint, iotta,*/ ROUND((CASE WHEN iotta=0 OR ipages=0 THEN 0.0 ELSE ipages::float/iotta END)::numeric,1) AS ibloat, CASE WHEN ipages &lt; iotta THEN 0 ELSE bs*(ipages-iotta) END AS wastedibytes FROM ( SELECT schemaname, tablename, cc.reltuples, cc.relpages, bs, CEIL((cc.reltuples*((datahdr+ma- (CASE WHEN datahdr%ma=0 THEN ma ELSE datahdr%ma END))+nullhdr2+4))/(bs-20::float)) AS otta, COALESCE(c2.relname,'?') AS iname, COALESCE(c2.reltuples,0) AS ituples, COALESCE(c2.relpages,0) AS ipages, COALESCE(CEIL((c2.reltuples*(datahdr-12))/(bs-20::float)),0) AS iotta /* very rough approximation, assumes all cols */ FROM ( SELECT ma,bs,schemaname,tablename, (datawidth+(hdr+ma-(case when hdr%ma=0 THEN ma ELSE hdr%ma END)))::numeric AS datahdr, (maxfracsum*(nullhdr+ma-(case when nullhdr%ma=0 THEN ma ELSE nullhdr%ma END))) AS nullhdr2 FROM ( SELECT schemaname, tablename, hdr, ma, bs, SUM((1-null_frac)*avg_width) AS datawidth, MAX(null_frac) AS maxfracsum, hdr+( SELECT 1+count(*)/8 FROM pg_stats s2 WHERE null_frac&lt;&gt;0 AND s2.schemaname = s.schemaname AND s2.tablename = s.tablename ) AS nullhdr FROM pg_stats s, ( SELECT (SELECT current_setting('block_size')::numeric) AS bs, CASE WHEN substring(v,12,3) IN ('8.0','8.1','8.2') THEN 27 ELSE 23 END AS hdr, CASE WHEN v ~ 'mingw32' THEN 8 ELSE 4 END AS ma FROM (SELECT version() AS v) AS foo ) AS constants GROUP BY 1,2,3,4,5 ) AS foo ) AS rs JOIN pg_class cc ON cc.relname = rs.tablename JOIN pg_namespace nn ON cc.relnamespace = nn.oid AND nn.nspname = rs.schemaname AND nn.nspname &lt;&gt; 'information_schema' LEFT JOIN pg_index i ON indrelid = cc.oid LEFT JOIN pg_class c2 ON c2.oid = i.indexrelid ) AS sml ORDER BY wastedbytes DESC;Раздувание базы данных - это дисковое пространство, которое использовалось таблицей или индексом и доступно для повторного использования базой данных, но не было освобождено. Раздувание происходит при обновлении таблиц или индексов. Если у вас загруженная база данных с большим количеством операций удаления, раздувание может оставить много неиспользуемого пространства в вашей базе данных и повлиять на производительность, если его не убрать. Показатели wastedbytes для таблиц и wastedibytes для индексов покажет вам, есть ли у вас какие-либо серьезные проблемы с раздуванием. Для борьбы с раздуванием существует команда VACUUM.6. Проверка запусков VACUUMSELECT relname, last_vacuum, last_autovacuum FROM pg_stat_user_tables;Раздувание можно уменьшить с помощью команды VACUUM, но также PostgreSQL поддерживает AUTOVACUUM. О его настройке можно прочитать тут.Ещё несколько запросов, которые могут быть вам полезны1. Показывает количество открытых подключенийSELECT COUNT(*) as connections, backend_type FROM pg_stat_activity where state = 'active' OR state = 'idle' GROUP BY backend_type ORDER BY connections DESC;Показывает открытые подключения ко всем базам данных в вашем экземпляре PostgreSQL. Если у вас несколько баз данных в одном PostgreSQL, то в условие WHERE стоит добавить datname = 'Ваша_база_данных'.2. Показывает выполняющиеся запросыSELECT pid, age(clock_timestamp(), query_start), usename, query, state FROM pg_stat_activity WHERE state != 'idle' AND query NOT ILIKE '%pg_stat_activity%' ORDER BY query_start desc;Показывает выполняющиеся запросы и их длительность.ЗаключениеВсе запросы выше собраны мной из интернета при появлении каких-либо вопросов или проблем в моей базе данных. Если есть ещё запросы, которые могут быть полезны для пользователей PostgreSQL, буду рад, если вы поделитесь ими в комментариях. Надеюсь, статья поможет вам и сохранит ваше время.</td>\n",
       "      <td>+76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>25  декабря  2017</td>\n",
       "      <td>Новый подход к спортивному анализу данных: какие шаблоны «рвет» SDSJ</td>\n",
       "      <td>https://habr.com/ru/article/344806/</td>\n",
       "      <td>Специалистам по data science сейчас есть где разгуляться — один Kaggle с его активностью по спортивному анализу данных чего стоит. Но время идет и метрики, по которым определяются победители конкурсов, постепенно устаревают или приедаются — в большинстве случаев используются классические выборки данных. А что, если вместо этого предложить разработать полноценную модель в Docker с конечным решением-моделью?Таким путем пошел Сбербанк. В ноябре в рамках серии мероприятий по машинному обучению и искусственному интеллекту Sberbank Data Science Journey на онлайн-соревновании Data Science Contest задачи были именно «докерными». Финальное мероприятие Sberbank Data Science Day и подведение итогов конкурса с призовым фондом в 2 миллиона рублей прошло 11 ноября в Tesla Place.Мы там были и активно общались со спикерами и участниками. Андрей Черток, глава исследовательского подразделения Сбербанка в общении задал тон остальным спикерам. В перерывах удалось поймать одного из организаторов — Алексея Натекина, — одного из спикеров — Михаила Бурцева и среди участников — Сергея Свиридова.Их мы расспросили про новый формат, «передали привет» Kaggle, нашли новую, неожиданную сторону докерных конкурсов и вытащили оптимальные алгоритмы ML для победы. Но обо всем по порядку.— Как вы оцениваете результаты мероприятия?— По сравнению с прошлым годом, мы вышли на новый уровень — по количеству участников Sberbank Data Science Day, по уровню спикеров и по сложности задач. В рамках соревнования мы создали первый в России набор данных для создания вопросно-ответных систем, аналог американского датасета. Это можно считать достижением для всего переднего края русскоязычных датасетов, комьюнити по диалоговым системам и задачам анализа текстов.— Какие практические цели ставил Сбербанк, устраивая конкурс?—  Сейчас актуальны задачи по созданию диалоговых систем, в частности, вопросно-ответных систем. На прошлой неделе мы вернулись с международной конференции NIPS, где этой теме было посвящено множество секций. Мы не хотим отставать, и наш конкурс, надеемся, помогает российскому научному сообществу в решении этой сложной задачи, связанной с созданием диалоговых систем и датасетов. Также мы заинтересованы в развитии технологий, связанных с диалоговыми системами, так как наш банк проходит существенную цифровую трансформацию.  Мы заинтересованы во внедрении технологий в банковскую сферу. Благодаря таким соревнованиям, мы находим людей и получаем алгоритмы, модели и продукты, которые внедряем в бизнес-процессы банка. Еще одна важная цель - позиционирование банка как технологического лидера в области искусственного интеллекта. После таких конкурсов кто-то приходит к нам работать, с кем-то мы делаем совместные проекты. Это хороший драйвер для дальнейших активностей. — Сбербанк уделяет особое внимание BigData, развивает инфраструктуру, привлекает специалистов… А есть ли какие-то кейсы применения машинного обучения?BigData актуально для вопросов кибербезопасности: есть большой массив данных для анализа, есть проекты, где в автоматическом режиме решаются классические задачи антифрода. Еще один кейс — банковская ликвидность. Вся система банкоматов переходит на управление моделями МО, которая прогнозирует спрос наличности в банкоматах и оптимальным образом перераспределяет ее во всей сети. — Да, конечно. Наша AI-трансформация осуществляется и благодаря внедрению моделей машинного обучения в те или иные процессы банка. Ведется реестр моделей инициатив от разных блоков, создано сообщество датасайнтистов в банке. Насчитывается порядка нескольких сотен проектов по внедрению моделей машинного обучения и автоматизации процессов в повседневные бизнес-задачи. Модели скоринга, модели принятия решений о выдаче кредитов для юридических и корпоративных клиентов, розничный бизнес: таргетинг, взаимодействие с клиентом, формирования предложения о продуктах. Практически все автоматизировано, везде используются модели машинного обучения. В общем, модели и алгоритмы, основанные на анализе больших данных, создаются для оптимизации тех или иных процессов, уменьшения затрат на эти процессы, улучшения клиентского опыта при взаимодействии с банком. Серьезная тема связана с анализом тестов, НЛП, диалоговыми системами. Уже сейчас есть достаточно кейсов, где мы внедряем эти технологии. А в ближайшие месяцы мы планируем запустить несколько проектов, автоматизированных за счет моделей машинного обучения. — В феврале вы рассказывали о разработке чат-бота. На какой стадии он сейчас?— Есть несколько чат-ботов, каждый создан для решения различных задач. Некоторые уже в продакшене, некоторые на стадии пилотирования. Уровень развития технологии остановился на стадии сценарных алгоритмов. Нам нужно заранее прописать некий алгоритм действий, которому будет следовать чат-бот. На данный момент это скорее \"умный поисковик\" по базе данных. Это новый для нас вызов: нужно создать системы, способные улавливать контекст общения с клиентом и персонифицировать его. Еще есть риск, что такие чат-боты могут неверно понять вопрос клиента и ответить какую-то глупость. Процент ситуаций, когда бот неправильно понимает контекст или вопрос, сейчас достигает 15%. Это недопустимый уровень, чтобы полноценно внедрять текущие решения. Мы прогнозируем в течение 2-3 лет создание более тонких и точных систем, и здесь у нас есть целый ряд проектов, в том числе, с университетами. В качестве примера можно привести iPavlov с физтехом. Здесь ведется большая работа. Чтобы решать такие задачи, мы проводим подобные соревнования, сотрудничаем с лабораториями и привлекаем в банк самых лучших людей. — Почему решили сменить формат конкурса и во что это вылилось?— Да, в этот раз совершенно новый формат конкурса — «докерные» решения, и к нему нужен новый подход. Специалистам гораздо привычней работать с csv и подгонять данные под выборку, а здесь мы требуем полностью рабочую модель. Была мысль использовать телеграм-бота, но побоялись сжечь все ресурсы еще до подведения итогов конкурса.«Докерные» задачи хороши тем, что на выходе получается воспроизводимое решение, пусть его делать дольше и сложнее. Такие задачи защищены от «болячек» Kaggle — нельзя разместить тестовую выборку и искать утечки.На Kaggle существует масса конкурсов с какими-то уязвимостями: либо нет рандомных классов, либо находятся утечки данных по результатам лидерборда. Здесь же такое не проходит: у участников просто нет доступа к тестовому множеству. Если бы по условиям конкурса не сказали, сколько в тестовом множестве точек, участники бы самостоятельно не могли это никак узнать. Конечно, алгебраически можно проверить, что в множестве содержится именно указанное количество точек. Но это нетривиально и требует огромных усилий.Вообще, «докерный» конкурс по вычислительным мощностям обходится тяжело — прислали суммарно около 5500 тысяч решений по задаче А и 1200 решений по задаче Б. Разница в ресурсоемкости при проверке задачи Б по сравнению с задачей А была примерно в 20000 раз. Было «сожжено» около 500 часов работы супермощной многоядерной машины.— Почему именно Docker?— Хотелось сделать что-то крутое. Есть такая штука как SQAD — Stanford question answering dataset. По сути, для конкурса собрали такой датасет для русского языка. Получилось даже больше участников, чем на SQAD'e, при этом SQAD'ом занимается профессиональная лаборатория на протяжении полутора лет. Приятно видеть, что человек с первого места в  конкурсе смог даже на небольшом датасете получить качество. В итоге, эксперимент получился удачным. Дальше будет все больше и больше аналогичных конкурсов.— Как думаете, в чем основная проблема типичных csv-like конкурсов?— В соревнованиях должна появляться какая-то конструктивная составляющая. Грустно наблюдать, что последние несколько лет каждое третье соревнование содержит серьезные недочеты. Поначалу это было на грани между «обидно» и «интересно». Вроде бы, появлялись какие-то новые челленджи с точки зрения безопасности. Потом люди привыкли к этому и стали уже с готовностью искать в данных лики. Сейчас это скорее популярный мемасик: люди смеются над тем, что лидерборд очередного конкурса на Kaggle состоит практически целиком из идеальной метрики.— Ты думаешь, что Kaggle будет постепенно переходить к формату «докерных» соревнований?— Kaggle давно пора нанять хотя бы одного data scientist'а, который будет прорешивать конкурсы. Будем честны, «утекший» конкурс — это целиком проваленное соревнование. Если бы у них были люди, которые в этом хоть немного разбираются, дело обстояло бы лучше.Если «докерных» соревнований будет больше, это приведет к совершенно новым возможностям как для отдельных людей, так и для больших компаний. После проведения таких конкурсов, может быть, начнут появляться marketplace решения. Сейчас у желающих отдать задачу на аутсорс есть два выхода: можно либо купить доступ к какой-нибудь API с надеждой, что она сделана не совсем криво, или обратиться к аутсорсерам/консалтерам и думать, что они сделают что-то сопоставимое по качеству. «Докерный» формат соревнований предлагает альтернативу. Это отличный способ решения задач внешними для компании людьми.— А сейчас часто практикуется схема, когда несколько моделей обучают путем конкуренции друг с другом (например, заставляют двух чат-ботов общаться друг с другом)?— Такое, конечно же, есть. Вот простой пример. Как-то мы взяли нашего чат-бота и заставили общаться сам с собой: то, что он говорил, отправлялось ему же. Озвучили мы это голосами из Yandex SpeechKit. Получилось прикольно, подняли себе настроение.Теперь более серьезный пример. Предположим, мы купили API Алисы из Яндекса и хотим разобрать его по кусочкам: часть блоков оставить, часть переиспользовать, часть написать самостоятельно и в итоге создать новый продукт на базе уже готовой технологии. «Докерный» формат разработки очень бы облегчил нам эту задачу. Конечно, Алиса — не очень правильный пример. Это сложная система, рассчитанная на большое количество пользователей. Мне сложно представить себе какой-нибудь CRT, который сможет разобрать Алису по частям.Более удачный вариант: выложенные в open source решения для предсказания временных рядов. Типичные решения, побитые на простые блоки и готовые работать с вашими данными, были бы интересны людям и пользовались спросом.— Расскажите, какие технологии использовали участники конкурса? Потенциальные победители обучали нейронки или использовали другие подходы?— Сейчас так или иначе топ-10 лидерборда использует архитектуру DRQA, разработанную командой FAIR (Facebok AI Research). Есть ребята из топ-10, которые сказали, что у них в основе лежит не сам DRQA, а какой-то немного по-другому навороченный bidirectionаl, attention плюс еще что-то. Но в любом случае у всех из топ-10 в основе лежали рекуррентные нейронные сети. Надо было брать внешние эмбеддинги, потому что самостоятельно на датасете вопросов-ответов эмбеддинг нормально не обучишь.В оригинальной статье про DRQA парни из Facebook советовали брать предобученный эмбеддинг, а потом подгонять его. Среди топ-1000 должны быть первые слова вопросов: «Как», «Когда», «Какой» и т.д.— Для обучения нейросетей нужно много вычислительных ресурсов. Как эту проблему решали участники конкурса?— Сами LSTM обучались не так долго, как мы ожидали. Одной видеокарточки за глаза хватало. За ночь получить какой-то приемлемый результат точно было можно.Есть нюанс про связь между использованием нейросетей, вычислительными ресурсами и конкурсами. Сейчас на задачах, где может помогать deep learning, проявляется интересный эффект: доминирование GPU. Во многих конкурсах без видеокарточек вообще никак не получится конкурировать с другими участниками. Например, на идущем сейчас на kaggle конкурсе discount у ребят одна эпоха обучается несколько дней.Была вероятность, что у нас обязательным условием победы тоже станет наличие GPU. Но первый же участник, который корректно обучил DRQA для наших данных, справился без наличия огромных вычислительных мощностей. На встрече на одной из ML-тренировок он рассказал, что все учил на CPU, видеокарточки у него нет.Итог: не всегда нужно больше слоев. «More layers» — это скорее мем, или же случай из жизни представителя очень серьезной лаборатории, у которой видеокарточек столько, что можно шутки ради смотреть как быстро обучается ImageNet, а также играться в meta-learning. Нормальный meta-learining начался со статей про «Learn gradient descent using gradient descent». Типичный пример: одной нейронной сетью ты учишь более сложные архитектуры решать задачи, например, обучать новые правила оптимизации. Таким в Гугле занимаются, и очень успешно.— Как вам в целом мероприятие? Оправдала ли цель средства?— Я принимал участие в разработке и организации Sberbank Data Science Journey, было интересно посмотреть, что получится. Я перфекционист — думаю, некоторое можно было сделать лучше или вообще поменять. Очень приятно, что практически не было ограничений ресурсов: большой зал, огромные экраны — инфраструктура что надо.— Получилось ли сделать «идеальную» для data scientist'а программу?— Одна из главных задач - постараться оставить довольными всех: на этом мероприятии есть и награждение, и бизнес-секции, и доклады для data scientist'ов.С точки зрения реализации, а также оценок «получилось/не получилось» очень сложно что-то говорить. Мы обсуждаем это посреди мероприятия, но уже можно сказать, что как бы ни было грустно, титул самого популярного и посещаемого мероприятия в СНГ по data science перешел на какое-то время от Data Fest к тому, что происходит здесь. На Data Fest было около 1700 человек, а у нас было 1750 розданных бейджиков уже с самого утра. Я думаю, будет 2100-2200. Зарегистрировалось 3400 человек.— Как вы прокомментируете формат посылок в соревновании? «Докерный» формат против классических csv'шек?— Этот конкурс далеко не первый, где используются докерные посылки. Мы делали аналогичную вещь, но более кустарным способом. Сейчас мы делаем соревнование для NIPS (NIPS Conversational Challenge). Там боты из разных институтов общаются с людьми, а люди оценивают их умение вести беседу. Эти боты запущены на нашей инфраструктуре. Для интерактивных задач это единственный способ адекватно оценить качество модели. Кроме того, такой подход позволяет избежать читерства: ты получил код, знаешь, что он не имеет доступа ни к каким внешним ресурсам.— Применяется ли такой подход к оцениванию моделей в бизнесе/промышленных задачах?— Да, такой подход применяется все чаще и чаще. Тендер — это фактически соревнование. Почему Google купил Kaggle? Они освоили соревновательное оценивание моделей, сделали marketplace для поиска решений нестандартных задач крупными компаниями. Идеология соревнований начинает использоваться все чаще. Она позволяет людям удаленно участвовать в конкурсах и удаленно презентовать решения тем, кто заинтересовался задачей. Такая среда помогает людям находить друг друга. Получается настоящий dating сервис для data scientist'ов.— Как тебе мероприятие в целом?— С моей точки зрения, все отлично сделано. Люди пришли, общаются. Очень удобно, что в дальней части зала лекция идет, а здесь можно стоять, разговаривать. Еще понравилось, что пригласили хороших выступающих. Думаю, что мероприятие уже удалось, хоть оно еще и не закончилось.— Участвовали ли Вы или, может быть, ваши ребята из iPavlov в контесте?— Поскольку мы аффилированы с этим проектом, нам не удалось поучаствовать в соревновании. Один из компонентов ведения диалогов — это ответы на вопросы. Для этого соревнования был создан специальный набор данных на русском языке, аналог американского датасета. Это открывает совершенно новые возможности для построения диалоговых систем и раскрутке их на российском рынке.— Что скажешь про «докерный» формат конкурса? Может быть, стоило провести соревнование в типичном для кэглеров формате?— Сейчас есть общая тенденция на подобные вещи: выгружать в качестве результата не просто метки классов, а готовый работающий прототип. Все используют разные подходы, библиотеки. Возможность у себя развернуть чужое решение и понять, как оно работает — это очень эффективный подход.— Какие алгоритмы машинного обучения кажутся тебе подходящими для решения задач конкурса?— Хочу отметить RL, эта область сейчас активно развивается. На данном этапе практических хороших результатов не так много, все они сосредоточены внутри крупных компаний. Но я думаю, что продвижение RL в бизнес — вопрос всего пары лет.— А что насчет хайпа вокруг нейронных сетей? Оправдан ли он?— Нейронная сеть — универсальный аппроксиматор. Хорошо обученная сеть позволяет получать адекватные результаты. Прорывы в deep RL были вызваны тем, что мы совместили хорошо известные еще с 70-80-х подходы reinforcement learning с глубокими нейронными сетями. К тому же, с использованием нейронной сети нам не нужно генерировать фичи, сеть сама выучивает представление.— Как тебе мероприятие в целом?— В целом очень понравилось. Организация на высоком уровне: и техническая часть, докладчики, тайминги, процесс с точки зрения пропусков, фуршеты. Редко такое встретишь на конференциях, многие часто фейлятся и забывают какие-то важные детали. Очень приятно, что на это мероприятие есть спрос: приходят как начинающие, так и профессионалы.— Участвовал в контесте? Решал обе задачи?— Я участвовал только в одной части, но у меня не было на это достаточно времени. Добрался до 20 места и на этом остановился.Все спикеры единогласны: машинное обучение уже давно перестало быть игрушкой и становится серьезным инструментом, решающим бизнес-задачи. Усложнение конкурсов, объединение энтузиастов в группы и приобретение стартапов крупными корпорациями — очередной шаг в расширении и масштабировании новых технологий. Что же будет дальше?</td>\n",
       "      <td>+21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>28  сентября  2018</td>\n",
       "      <td>Приглашаем на Sberbank Data Science Journey 2018 — гонку алгоритмов машинного обучения</td>\n",
       "      <td>https://habr.com/ru/company/sberbank/blog/424635/</td>\n",
       "      <td>Этой осенью мы вновь организуем большое соревнование по машинному обучению Sberbank Data Science Journey. Каждый год мы охватываем какую-то новую тему и теперь приглашаем вас попробовать силы в AutoML. Если конкретнее — в разработке очень умелого мета-алгоритма, способного самостоятельно создавать модели машинного обучения: с обработкой данных, построением признаков, обучением моделей, подбором их параметров и предсказанием целевой переменной. В этом году за решение задачи мы наградим сразу 13 команд. Остальные подробности — далее в посте. Условия и расписание Условия задачи этого года подробно изложены на GitHub. Если вкратце, то нужно создать алгоритм машинного обучения, который автоматически выполняет предобработку данных, выбор семейства моделей, а также подбор гиперпараметров. И, конечно, соответствует всем поставленным условиям. Для работы, помимо этих условий, дается публичный набор датасетов. Каждой команде участников будет предоставлен личный кабинет на сайте конкурса. В команду могут входить максимум четыре человека. Во время соревнования, с 19 сентября по 3 ноября участники смогут загружать в личный кабинет до пяти решений-алгоритмов ежедневно. Все эти решения попадают в общий рейтинг, где в режиме онлайн регулярно проверяются на наборе закрытых тестовых данных. Из результатов составляется таблица общего зачета, открытая всем — можно всегда прикинуть свои успехи. Загрузка решений будет доступна до 3 ноября, 23:59:59 (здесь и далее — по московскому времени). Среди всех своих загруженных решений каждая команда должна будет выбрать два, которые представят ее в финале. На это дополнительно дается 12 часов. Дедлайн по выбору — 4 ноября, 12:00. И наконец, следующие 12 часов мы будем прогонять данные на финальных решениях и объявим призерова на сайте соревнования к концу этого периода. Награды Разработчики десяти решений с наибольшим итоговым рейтингом будут награждены денежными призами: 1 000 000 рублей за первое место, 500 000 — за второе, 300 000 — за третье, 200 000 — за четвертое и пятое. Все остальные места до десятого включительно получат по 100 000 рублей. Кроме того, если команда не поленится опубликовать решение на GitHub, то может получить еще 100 000 рублей. Мы разыграем три таких премии среди наилучших решений, которые будут выложены для публичного пользования. И кстати, этот дополнительный приз не исключает основной. Официальное награждение пройдет 10 ноября на конференции «Sberbank Data Science Day». О конфе мы еще напишем дополнительно. Транспортные расходы разработчиков из других городов берем на себя, но даже если и это не заманит вас в столицу, приз все равно выплатим. На случай разных непоняток вся информация о мероприятии сухим юридическим языком доступна в отдельном документе. Если не нашли ответ там или вопрос касается технической части, задавайте его на форуме или в комментариях к посту. Будем рады вашему участию! Полезные ссылки: Сайт Sberbank Data Science Journey 2018 Интервью с участниками и организаторами SDSJ 2017 Отчет с SDSJ 2016</td>\n",
       "      <td>+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9  ноября  2018</td>\n",
       "      <td>Прямая трансляция Sberbank Data Science Day 10 ноября</td>\n",
       "      <td>https://habr.com/ru/company/sberbank/blog/429320/</td>\n",
       "      <td>Привет! 10 ноября (уже завтра!) в Москве в киноцентре «Октябрь» пройдет большая конференция Sberbank Data Science Day, где будут награждение победителей SDSJ 2018, выступления большого количества международных и российских экспертов в области Data Science, секции про ML и применение искусственного интеллекта в науке и бизнесе. И еще много интересного! Прямую трансляцию можно посмотреть тут. Под катом и на сайте программа. Также рассказываем, как оценивали победителей Sberbank Data Science Journey. Программа Конференция разделена на несколько тематических блоков, вот расписание: Основной зал 11:00 – 11:30. Открытие конференции. 11:30 – 12:30. Панельная дискуссия «Технологии анализа данных и искусственного интеллекта в цифровой экономике» 12:30 – 13:15. «Биологически-обусловленные методы и архитектуры в глубоком обучении». Сергей Бартунов, Deep Mind 13:15 – 14:00. «Conversational Agents as Intelligent Digital Companion to Understand Human Emotion and Express its Emotion». Soo-Young Lee, KAIST 15:00 – 15:45. «Масштабируемое автоматическое машинное обучение». Андрей Спиридонов, H2O 15:45 – 16:30. Панельная дискуссия «Тренд на инновации: применение DS/AI и улучшение клиентского опыта» 17:15 – 18:00 Торжественное награждение победителей соревнований Sberbank Data Science Journey и КлассикAI (соревнование по стихосложению с помощью искусственного интеллекта) Зал «Наука» 12:30 – 13:45.DS/AI технологии: AutoML 13:45 – 14:45.DS/AI технологии: Computer Vision 14:45 – 15:45.DS/AI технологии: Natural Language Processing (NLP) 15:45 – 16:30.DS/AI технологии: Reinforcement Learning 16:30 – 17:15.DS/AI технологии: Speech Analytics Зал «Бизнес» (зал 1) 12:30 – 13:45.Применение DS/AI в банковской и финансовой сферах 13:45 – 15:00.Применение DS/AI в медицине и биоинформатике 15:00 – 16:15.Применение DS/AI в банковской и финансовой сферах 16:15 – 17:15.Brainwriting: создаем платформу для AI исследований Зал «Бизнес» (зал 2) 12:30 – 14:45.Применение DS/AI в ритейле 14:45 – 16:30.Применение DS/AI в промышленности 16:30 – 17:15.Применение DS/AI в медиа и телекоме Зал «Сообщество» 12:30 – 13:15.Презентация постеров «Poster Session Lightning Talk» 13:15 – 15:00.Презентация открытых проектов в сфере DS/AI «AI Open Projects» 15:00 – 15:45.Разбор решений соревнования КлассикAI 15:45 – 17:15.Разбор решений соревнования Sberbank Data Science Journey Победители Sberbank Data Science Journey В этом году мы предложили решить задачи c использованием технологии AutoML. До конца 3 ноября участники выгружали свои решения, в следующие 12 часов выбирали из своих решений лучшие. Теперь выбор за жюри. На конференции мы наградим победителей Sberbank Data Science Journey. Участникам были предоставлены готовые наборы данных от Сбербанка. Все 24 датасета, задействованных в соревновании, были собраны различными департаментами: блоком розницы, блоком рисков и блоком технологий. Все они были специальным образом подготовлены и обезличены. В основу легла такая информация, как: Доля одобренного лимита Время доставки карты Различные виды скоринга Отклики на предложение карты Отклик на прочие предложения продуктов Поломки банкоматов Информация о снятии наличных в банкоматах Остатки средств на счетах и другая информация Для оценивания решений были выделены группы датасетов: check (открытый для участников), public (скрытый от участников, но можно видеть результат во время соревнования), private (набор, на котором подводятся итоги соревнования) В каждом таком наборе три задачи на регрессию и пять на бинарную классификацию. Решения работали на наборах данных различных размеров: от 1Мб и 300 строк до 1Гб и 1млн строк. Жюри еще до начала соревнования подготовило датасеты, тестирующая система уже проверила их в автоматическом режиме, а на сайте сейчас можно видеть результаты (с учетом ограничений, связанных с интригой). Решения принимались в формате архивов с кодом. Участникам нужно было построить алгоритм, который реализует полный цикл решения задачи машинного обучения автоматически, получая на вход данные, а на выходе возвращая готовый ответ. Решения участников должны были вписаться в заданные ограничения: решению доступны ресурсы решение не имеет доступа к ресурсам интернета максимальный размер упакованного и распакованного архива с решением: 1 Гб архив распаковывается в файловую систему, находящуюся в оперативной памяти (ramfs), доступную решению для записи остальное содержимое контейнера доступно только для чтения CSV с набором данных не превышает 3 Гб Ограничения нужны для того, чтобы достичь честного сравнения, поставив участников в равные технические условия. Вот что представляет собой система оценки в данном соревновании: Для каждой задачи (датасету) по тестовой части выборки считается метрика, специфичная для задачи (RMSE для регрессии, ROC-AUC для бинарной классификации). Для каждой задачи (датасета) производится перевод значения метрик участников в общую шкалу по следующей схеме. За наилучшее по метрике решение (среди всех отправленных и успешно протестированных решений) дается 1 балл, бейзлайн-решение оценивается в 0 баллов. Участники, находящиеся по метрике между наилучшим и бейзлайн-решениями получают пропорциональное количество баллов между 0 и 1. Решения по качество нижу бейзлайна оцениваются в 0 баллов. Если наилучшее решение и бейзлайн решения совпадают, то все участники получают 0 баллов. Если решение участника выдаёт на задаче ошибку или не проходит по временному ограничению, то оно получают за эту задачу 0 баллов. Итоговый результат каждого участника считается как сумма результатов по каждой задачи после преобразования в общую шкалу. В общем лидерборде участники ранжируются по итоговому результату. Итоги соревнования доступны здесь. Кроме основного зачета, участники боролись за приз в номинации “Лучшее публичное решение”. На протяжении всего конкурса они публиковали свои подходы к решению задачи AutoML на GitHub, а победители определились по количеству GItHub stars. На конференции будет отдельная секция, посвященная SDSJ’18, где победители расскажут о своих решениях и ответят на все вопросы. Еще раз оставляем ссылку на онлайн трансляцию конференции, чтобы все заинтересовавшиеся могли посмотреть Sberbank Data Science Day.</td>\n",
       "      <td>+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>28  декабря  2016</td>\n",
       "      <td>Отчёт со Sberbank Data Science Day: решения, победители, интервью</td>\n",
       "      <td>https://habr.com/ru/article/318160/</td>\n",
       "      <td>В ноябре Сбербанк провел серию мероприятий по машинному обучению и искусственному интеллекту Sberbank Data Science Journey. Финальное мероприятие, Data Science Day, прошло 12-го ноября на площадке DI Telegraph. Его посетило более 1000 человек.Data Science Day завершал месячный конкурс, ставший самым крупным по количеству участников и зарегистрировавшихся в СНГ: более 700 человек отправили свои решения, более 3000 зарегистрированных участников работали с данными, а также сгенерировали более 30Гб данных.  Data Science Day открылся видео-приветствием Германа Грефа. Затем пришедших data scientists со сцены поприветствовал Заместитель Председателя Правления Сбербанка Вадим Кулик.Вадим Кулик рассказал об основных принципах data-driven организаций, требованиях к современным ИТ-платформам и о стратегических направлениях развития технологий Сбербанка.Далее на сцену поднялся старший вице-президент Сбербанка Александр Ведяхин и рассказал об интересных кейсах Сбербанка в области машинного обучения и искусственного интеллекта.Следующий блок открывали приглашённые специалисты мирового уровня в области анализа данных и искусственного интеллекта. Профессор Университета Амстердама Маартин де Рийке на примере задач информационного поиска рассказал про бурно развивающуюся парадигму Reinforcement Learning, являющуюся предвестником искусственного интеллекта в его широком понимании. Уже сейчас в банке начинаются эксперименты с данным подходом при решении прикладных задач (рекомендательные системы, персональные предложения клиентам).Senior Data-Scientist международной компании H2O Дмитрий Ларько рассказал про одну из самых важных проблем использования методов машинного обучения - интерпретируемость получаемых результатов (проблема \"чёрного ящика\"). Дмитрий рассмотрел подходы к интерпретации результатов, полученных в ходе применения таких моделей, которые могут значительно улучшить доверие бизнес-аналитиков к использованию современных методов машинного обучения.Выступление профессора Константина Воронцова было посвящено изящному применению тематического моделирования для анализа транзакционных данных банка. Транзакционная история интерпретируется как набор предложений, а алгоритмы тематического моделирования позволяют выделить основные стереотипы поведения клиентов банка. Это даёт возможность более точно описывать группы клиентов для персональных предложений.Выступление Дмитрия Ветрова было посвящено актуальной теме стохастических вычислительных графов, которые в последний год получили широкое распространение в алгоритмах deep learning . Добавление случайных узлов значительно расширяет возможности применения данного метода машинного обучения и позволяет находить сложные зависимости в данных (распознавание изображений, машинный перевод, системы Q&amp;A). Этот подход имеет прямое применение при разработке более точных подходов к решению, в частности, задач банков, использующих методы машинного обучения.Конкурс состоял из двух частей: прием-онлайн заявок был открыт с 7 октября до 6 ноября , а финал конкурса состоялся 12 ноября на Data Science Day, куда были приглашены авторы 5 отобранных проектов-финалистов. Обязательным условием конкурса являлось то, что все проекты должны были основываться на данных банка (данные были обезличены и специальным образом модифицированы), но при этом было разрешено обогащать данные из открытых источников.  На основе полученных данных было необходимо выявить одну бизнес-задачу банка и разработать для неё решение. Технологический стек решений и тематика задач оставались на усмотрение участников.  По результатам онлайн-этапа было собрано 35 заявок от различных команд и стартапов в области дата-сайнс, среди которых были отобраны пять лучших команд. На Data Science Day состоялся финал конкурса в виде питч-сессий по 7 минут каждая. Победителей выбрало жюри, состоящее из топ-менеджеров Сбербанка и представителей компаний-партнёров.Все финалисты получили возможность встретиться с топ-менеджерами банка и обсудить возможности сотрудничества.Ниже мы опишем краткие тезисы проектов команд со ссылками на презентации.Команда 1Factor представила одно из наиболее интересных решений, использующее объединение разных типов данных: история транзакций клиентов (данные были обезличены и специальным образом модифицированы) и геолокационные данные. Наиболее ценным является алгоритм, который находит соответствия между этими данными при том, что оба датасета являлись обезличенными! После того, как удалось сделать такой матчинг данных, стало возможным отслеживать перемещения клиентов и, как следствие, выяснять популярность у этих клиентов тех или иных предприятий малого и среднего бизнеса. Анализ динамики трафика клиентов предприятий позволяет, в частности, оценивать кредитные риски такой организации, что, несомненно, представляет большую ценность для банка. Решением жюри команда участвовала в соревновании вне конкурса, но получила специальный приз \"за лучшую синергию данных\". Команда RooX Solutions представила проект по выработке рекомендаций клиентам банка на основе анализа транзакций для повышения благосостояния. В частности, речь идёт об увеличении накоплений, о льготном кредитовании кассовых разрывов или временном ограничении необязательных расходов. Особенностью проекта стало объединение экспертной экономической модели и алгоритмов машинного обучения для прогнозирования и генерации сигналов для клиентов в нужный момент.  Модель включала в себя индексы роста благосостояния и финансовой стабильности (см. рисунок), т.е. устойчивости клиента к возможным внезапным сокращениям доходов. На основании прогноза постоянных и переменных расходов и доходов за месяц, а также значений индексов и анализа их волатильности определялись клиенты, которым окажутся полезными те или иные рекомендации. Ещё одной особенностью проекта являлось то, что для решения задачи прогнозирования команда использовала регрессию с доверительными интервалами и делала прогноз не на месяц вперёд, а до конца текущего месяца. Таким образом удалось получить сужающиеся по ходу месяца интервалы и, начиная где-то с середины месяца, достаточную уверенность в прогнозе для того, чтобы делать обоснованные рекомендации.Команда  Alone.io объективно являлась самой сильной среди всех команд с точки зрения компетенций решения задач в области data science-В ее составе - двое из списка Топ-20 Kaggle. Один из них (Дмитрий Алтухов) занял второе место в нашем Data Science Contest. Свой бизнес-проект для Startup Challenge они построили на основе решения задачи из контеста о прогнозировании трат клиентов в различных категориях (так называемых MCC-кодах). Имея хороший алгоритм прогнозирования трат клиентов, например, в тех или иных категориях, можно предугадывать некоторые факты из жизни клиента (например, факт поездки за рубеж). Методом скользящего окна производится анализ покупок клиента и поиск закономерностей в его поведении. В случае пошагового анализа вероятность покупки увеличивается перед самим событием (см. рисунок). Данное решение можно использовать для увеличения взаимодействия с клиентом с помощью персональных предложений. Командой MCC2VEC были предложены модели с применением word2vec алгоритмов, переводящих слова в вектора. Разработанные в 2013 году командой разработчиков Google под руководством Томаса Миколова, на сегодняшний день подобные алгоритмы используются для интерпретации и написания текста. При этом участники предложили интерпретировать последовательность транзакций клиентов как текст. То есть транзакции клиента разбиваются на предложения, которые, в свою очередь, разделяются между собой точками в случае, если между ними более 12 часов.Выступающие в данном случае в роли «слов» MCC-коды, обрабатываются с помощью алгоритмов word2vec, в результате чего каждому коду соответствует стомерное представление, то есть просто стомерный вектор чисел. Два MCC-кода рассматриваются как близкие или далекие в зависимости от величины cos угла между ними. С учетом этого, для каждой MCC-траты клиента можно суммировать полученные вектора (с некоторыми нормализациями), напрямую соотнести клиента и получить client2vec.На следующем этапе применяется техника t-SNE или t-distributed stochastic neighbor embedding. После чего клиенты «проецируются» на двумерную плоскость, что позволяет выделить определенные кластеры. В итоге было получено 15 категорий клиентов, объединенных некими признаками.Аналогично данный алгоритм может быть использован в случае антифрода. В этом случае клиент и совершенная транзакция также соотносятся со стомерными векторами, после чего происходит оценка того, насколько эти вектора близки или далеки друг от друга, что помогает отметить нехарактерную для данного клиента операцию, а алгоритму при этом позволяет адаптироваться к изменениям в его поведении.Победителем Startup Challenge стала команда из Санкт-Петербурга SD Data. За неделю до Data Science Day они стали победителями хакатона Neurohack 2.0 в треке Сбербанка и фактически с решением, придуманным за 36 часов на самом хакатоне, были приглашены в финал. Поздравляем со столь впечатляющим результатом! Команда смогла \"запаковать\" в бизнес-решение достаточно простую идею о том, как можно искать подозрительные транзакции. Разработчики предложили отложить в системе координат по оси Х все сделанные клиентом переводы, а по оси Y – его покупки. При этом все переводы, находящиеся ниже биссектрисы угла Y0Х, отмечаются как подозрительные, так как находятся за пределами порога разумного числа переводов (количество покупок меньше, чем количество переводов).Фактически это один из возможных способов разметить выборку клиентов относительно мошеннических операций. Затем уже, используя различные методы машинного обучения (xgboost, k-means кластеризация), разработчики смогли расширить изначальный список подозрительных транзакций и выявить различные наиболее типичные схемы вывода денег и разбить их на основные типы (субъекты малого предпринимательства, мошенники, благотворительность). Например, были выявлены такие предполагаемые схемы как \"Прогон средств\" и \"Вывод денег за рубеж\" В качестве решения команда предложила ввести комиссию за получение входящих средств при превышении некоторого количества входящих переводов в месяц, установить минимальный временной промежуток для дальнейшего перевода средств, а также дополнительно изучать аккаунты с преобладающей нестандартной схемой вывода поступивших средств.В ноябре Сбербанк провел серию мероприятий по машинному обучению и искусственному интеллекту (SDSJ.ru), финальное мероприятие которого - Data Science Day - 12-го ноября на площадке DI Telegraph посетило более 1000 человек. Андрей Черток (директор по исследованиям и разработкам, Сбербанк) рассказал о ключевых аспектах, необходимых для проведения успешного соревнования в области анализа данных. Соревнование случилось благодаря объединению усилий большого количества людей с нужным набором компетенций. Отдельно было рассказано об институте соревнований и их полезности для бизнеса как об одном из инструментов выстраивания связей между компаниями, научным и data-science сообществами. Такого рода соревнования вряд ли могут иметь прямое business value для компаний как прямой инструмент решения прикладных задач в контексте прямого внедрения решений победителей в продакшн (за редким исключением). С другой стороны, открытость банка с точки зрения возможности поработать с реальными данными о транзакциях открывает много новых перспектив по развитию методов исследования данных. Принцип открытости сейчас заложен в основу развития многих мировых ИТ-компаний, одной из которых стремится стать Сбербанк.Александр Фонарёв (Chief Data Scientist, SBDA Rubbles) выступил с интересной лекцией о том, как проходила подготовка задач для соревнования. Организаторы потратили очень много времени на подготовку данных, корректную постановку задач и их тщательное прорешивание. Для того, чтобы соревнование было интересным для пользователей, нужно избежать большого количества проблем, таких как лики в данных, неустойчивость решений на обучающей и тестовой выборках, а также сделать постановки задач такими, чтобы они допускали выбор разных подходов к их решению, а также были достаточно интересными с точки зрения поиска наиболее эффективных признаков, которые подаются на вход в модели прогнозирования. Отдельной сложностью при подготовке соревнования был поиск оптимальной формулы расчёта итогового рейтинга и, в особенности, взвешивающих коэффициентов по задачам (для того, чтобы участники \"в среднем\" решали все задачи). Третье место в конкурсе занял Василий Рубцов. Василий представил решение по задаче B о прогнозировании суммарных трат всех клиентов на месяц вперёд в тех или иных категориях. Простые модели использовали линейные регрессии на основе средних (за последнюю неделю/месяц/год, средневзвешенные траты, среднее по дням недели) в качестве регрессоров. Более сложные модели строились либо как разность базовых, либо как их блендинг с некоторыми обобщениями.Дмитрий Алтухов, занявший в контесте второе место, рассказал о своих подходах к решению задачи C, в которой требовалось предсказать объём трат в следующем месяце в каждой из 184 категорий для 3000 пользователей. Структура решения, как обычно, состояла в применении достаточно стандартных подходов:    Извлечение базовых признаков. Для извлечения базовых признаков используем различные меры за последние пять месяцев (объём трат, количество трат и std трат) в различных измерениях (месяц, пользователь, mcc; месяц, пользователь; месяц, mcc).    Построение линейных моделей для каждого пользователя. У каждого пользователя выделялся уникальный характер трат (регулярность, количество), затем для каждого из них строилась сильно регуляризованная ridge-регрессия на базовых признаках;    Построение линейных моделей для каждого MCC-кода. Поскольку MCC-кодов было не так много, как пользователей, однако, структура трат по ним достаточно сложна для описания одной общей моделью. При этом можно заметить, что траты по некоторым кодам связаны друг с другом, поэтому помимо базовых признаков в модель добавлялись траты за предыдущий месяц по каждому из MCC-кодов;    Объединение всех признаков в XGBoost. В итоговую модель были включены как базовые признаки, так и предсказания, полученные с помощью пользовательских/MCC-регрессий.    Лёгкий постпроцессинг решений. Приведение решений к \"адекватному\" виду (например, если предсказание получилось меньше нуля, то в качестве ответа выдаём ноль). Дмитрий Афанасьев, занявший в соревновании первое место, рассказал о решении самой простой задачи о предсказании пола клиента по его транзакциям (пол был известен для 12000 человек, предлагалось вычислить вероятность оказаться мужчиной оставшимся 3000 клиентам). Основные наблюдения Дмитрия по поводу данных и контеста состояли в том, что из текстовых описаний MCC-кодов и типов транзакций тяжело что-то получить, при этом MCC-коды важнее типов транзакций. Специфика соревнования подсказывает, что обучение и корректная валидация моделей гораздо важнее, чем опора при поиске решения на результаты публичного рейтинга.  Задача выглядела достаточно классической, поэтому интуиция подсказывала, что наиболее оправданным является применение неглубоких деревьев с малым количеством признаков на агрегатах (на сырых транзакционных данных модели не работают). Базовые признаки были связаны со стандартными производными от трат (сумма, количество, min/max), параметры xgboost: eta = 0.02, depth = 3, subsample = 0.6. Ключевыми признаками также являлись \"мужские\" и \"женские\" траты в разрезах по различным MCC-категориям и типам транзакций и другие более специфические (например, объединение MCC-кодов в пары: если после покупки в магазине женской одежды идёт покупка в магазине мужской, то это снижает вероятность того, что данный клиент - женщина). Сверху также навешивался стекинг наивного байеса как признака, в котором траты в MCC-кодах использовались как простой bag of words. Более подробно про решение задачи A - в презентации (ссылка) и видео-выступлении (ссылка). В завершении Data Science Day у участников была возможность пообщаться в неформальной обстановке во время фуршета, приобрести новые, полезные контакты, и хорошо провести время.   Data Science Journey – это не просто разовое мероприятие в области анализа данных, машинного обучения и искусственного интеллекта, а начало новой и прочной традиции: такие «Путешествия» мы планируем проводить на регулярной основе. Ждите наших новых мероприятий!</td>\n",
       "      <td>+31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7  ноября  2017</td>\n",
       "      <td>Приглашаем на Sberbank Data Science Day 11 ноября</td>\n",
       "      <td>https://habr.com/ru/company/sberbank/blog/341814/</td>\n",
       "      <td>В эту субботу, 11 ноября, мы приглашаем читателей Хабра на однодневную конференцию по Data Science, Machine Learning и AI. Это мероприятие завершит Sberbank Data Science Journey, ежегодные соревнования по интеллектуальному анализу данных с применением передовых математических методов и алгоритмов. В этом году состязание проводилось на первом в своем роде русскоязычном наборе данных. Мы наградим победителей и послушаем выступления от ведущих исследователей Nate Kushman (MIT, Microsoft Research UK), Дмитрий Ветров (ФКН ВШЭ, Bayes Group), Михаил Бурцев (МФТИ, iPavlov), Евгений Бурнаев (Сколтех, ADASE group) и Александр Тужилин (New York University, Сбербанк AI Lab). Кроме того, на специальной секции про бизнес в AI о пути своих компаний и перспективах монетизации AI расскажут основатели компаний Prisma, NTechLab, Rubbles и Vision Labs. Подробная программа и ссылка на регистрацию — под катом. Место: Tesla Place (Шоссе Энтузиастов, 5) 10:00 — Регистрация гостей 11:00 — Открытие Sberbank Data Science Day: Герман Греф, Президент, Председатель Правления Сбербанка Александр Ведяхин, Старший вице-президент Сбербанка Keynote лекция: Nate Kushman, MIT, Microsoft Research UK, Christopher M. Bishop Research Group 13:00 — Панельная дискуссия STARTUP «Будущее за AI: перспективы использования AI технологий и способы их монетизации»: Алексей Моисеенков (Prisma) Артем Кухаренко (NTechLab) Алексей Нехаев (Vision Labs) Никита Блинов (Rubbles) 14:00 — Обеденный перерыв 15:00 — Machine Learning лекции: Михаил Бурцев, МФТИ, iPavlov: «Проект iPavlov: исследования и разработки в области разговорного искусственного интеллекта» Дмитрий Ветров, ФКН ВШЭ, Bayes Group: «Открытые проблемы в глубинном обучении: байесовское решение» Александр Тужилин, New York University, Сбербанк AI Lab: «Современные подходы к некоторым проблемам в рекомендательных системах» Евгений Бурнаев, Сколтех, ADASE group: «Современные подходы к распознаванию объектов и построение 3D моделей из разнородных данных» 17:45 — Data Science Contest awards: Награждение победителей по задаче А Интерактив, «Приз Жюри» Награждение победителей по задаче В 19:00 — Data Science Day wrap-up: Заключительное слово руководства Сбербанка Фуршет Участие бесплатное, нужна только регистрация: sdsj.timepad.ru/event/603431 До встречи!</td>\n",
       "      <td>+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "                  date                                              title  \\\n",
       "0    25  октября  2021  Ошибка в экспоненциальной форме записи чисел в...   \n",
       "1          7  апреля    Яндекс Практикум запускает курс «SQL для работ...   \n",
       "2       30  июня  2021  Решения Quest для управления и мониторинга Mic...   \n",
       "3        24  августа    Python, SQL, С и Java стали самыми популярными...   \n",
       "4        30  октября             Топ полезных SQL-запросов для PostgreSQL   \n",
       "5    22  декабря  2020  DataLine запускает кластер для нагруженных баз...   \n",
       "6    14  октября  2021          Бесплатный курс-симулятор: введение в SQL   \n",
       "7           21  июня    SQL Camp — летняя образовательная программа Ро...   \n",
       "8            5  июля    Разработчики Django исправили уязвимость, кото...   \n",
       "9     5  октября  2021  Внимание! Приглашаем программистов 1С и SQL к ...   \n",
       "10     7  апреля  2016  Разнообразие версий Microsoft SQL Server и как...   \n",
       "11    8  февраля  2011                                     FAQ: SQL Azure   \n",
       "12   24  октября  2012  Полное руководство: средства и способы миграци...   \n",
       "13      14  июня  2016  Полный список флагов трассировки Microsoft SQL...   \n",
       "14          25  июня    Технология SQL-файл, препроцессор для T-SQL, “...   \n",
       "15   16  августа  2012  Масштабирование и особенности разработки для S...   \n",
       "16  13  сентября  2012  Сравнивая и противопоставляя Windows Azure Tab...   \n",
       "17    9  октября  2012                      Генератор SQL запросов на PHP   \n",
       "18   13  декабря  2012  Всё что вы стеснялись спросить о бэкапах Micro...   \n",
       "19    29  апреля  2014  SQL Server в облаке Microsoft Azure: PaaS vs IaaS   \n",
       "20   25  декабря  2017  Новый подход к спортивному анализу данных: как...   \n",
       "21  28  сентября  2018  Приглашаем на Sberbank Data Science Journey 20...   \n",
       "22     9  ноября  2018  Прямая трансляция Sberbank Data Science Day 10...   \n",
       "23   28  декабря  2016  Отчёт со Sberbank Data Science Day: решения, п...   \n",
       "24     7  ноября  2017  Приглашаем на Sberbank Data Science Day 11 ноября   \n",
       "\n",
       "                                                 link  \\\n",
       "0                  https://habr.com/ru/news/t/585346/   \n",
       "1   https://habr.com/ru/company/yandex_praktikum/n...   \n",
       "2   https://habr.com/ru/company/galssoftware/news/...   \n",
       "3                  https://habr.com/ru/news/t/684376/   \n",
       "4                    https://habr.com/ru/post/696274/   \n",
       "5   https://habr.com/ru/company/dataline/news/t/53...   \n",
       "6   https://habr.com/ru/company/netologyru/news/t/...   \n",
       "7   https://habr.com/ru/company/rosbank/news/t/672...   \n",
       "8                  https://habr.com/ru/news/t/675074/   \n",
       "9                  https://habr.com/ru/news/t/581572/   \n",
       "10                   https://habr.com/ru/post/281194/   \n",
       "11                   https://habr.com/ru/post/113379/   \n",
       "12  https://habr.com/ru/company/microsoft/blog/155...   \n",
       "13                   https://habr.com/ru/post/303212/   \n",
       "14                   https://habr.com/ru/post/672084/   \n",
       "15  https://habr.com/ru/company/microsoft/blog/149...   \n",
       "16                   https://habr.com/ru/post/151394/   \n",
       "17                   https://habr.com/ru/post/154245/   \n",
       "18                   https://habr.com/ru/post/162497/   \n",
       "19  https://habr.com/ru/company/microsoft/blog/221...   \n",
       "20                https://habr.com/ru/article/344806/   \n",
       "21  https://habr.com/ru/company/sberbank/blog/424635/   \n",
       "22  https://habr.com/ru/company/sberbank/blog/429320/   \n",
       "23                https://habr.com/ru/article/318160/   \n",
       "24  https://habr.com/ru/company/sberbank/blog/341814/   \n",
       "\n",
       "                                                 text likes  \n",
       "0   Этичные хакеры из Go Secure обнаружили ошибку ...   +25  \n",
       "1   Яндекс Практикум разработал курс «SQL для рабо...    +2  \n",
       "2                                                        +3  \n",
       "3   Американский журнал IEEE Spectrum опубликовал ...    +3  \n",
       "4   Статей о работе с PostgreSQL и её преимущества...   +76  \n",
       "5   Новый кластер с Intel Optane, NVMe и процессор...    +5  \n",
       "6   С 15 октября начнётся курс Нетологии «Введение...    +3  \n",
       "7   Второй год подряд мы совместно с благотворител...     0  \n",
       "8   Разработчики опубликовали корректирующие выпус...    +3  \n",
       "9   14 октября 2021 года состоится Открытый Турнир...    +3  \n",
       "10  В свое время из-за немного громоздкой политики...    +8  \n",
       "11  В продолжение к FAQ по Windows Azure Platform ...   +11  \n",
       "12  В этом документе представлены рекомендации по ...    +1  \n",
       "13  Microsoft SQL Server Флаги Трассировки Полный ...    +9  \n",
       "14  Завершив в недавнем прошлом очередную доработк...    +1  \n",
       "15  Это вторая часть цикла про то, как устроена SQ...   +12  \n",
       "16  В этой статье приводится сравнение двух сервис...   +10  \n",
       "17  Где-то полтора года назад я начал заниматься w...   -21  \n",
       "18  В ходе проведения презентаций о бэкапах и восс...   +16  \n",
       "19  Путь к размещению SQL Server в любом облаке, б...    +6  \n",
       "20  Специалистам по data science сейчас есть где р...   +21  \n",
       "21  Этой осенью мы вновь организуем большое соревн...   +12  \n",
       "22  Привет! 10 ноября (уже завтра!) в Москве в кин...   +11  \n",
       "23  В ноябре Сбербанк провел серию мероприятий по ...   +31  \n",
       "24  В эту субботу, 11 ноября, мы приглашаем читате...   +11  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SDSJ\n",
    "search_habr_full(requests_list=[\"sql\", \"SDSJ\"], page_count=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
